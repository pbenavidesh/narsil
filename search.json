[
  {
    "objectID": "docs/ts_analysis/dummy_file.html",
    "href": "docs/ts_analysis/dummy_file.html",
    "title": "presentation_dummy",
    "section": "",
    "text": "Just as a tutorial\n```{r}\n1 + 1\n```",
    "crumbs": [
      "Models",
      "Univariate models",
      "Dummy file"
    ]
  },
  {
    "objectID": "docs/ts_analysis/dummy_file.html#first-slide",
    "href": "docs/ts_analysis/dummy_file.html#first-slide",
    "title": "presentation_dummy",
    "section": "",
    "text": "Just as a tutorial\n```{r}\n1 + 1\n```",
    "crumbs": [
      "Models",
      "Univariate models",
      "Dummy file"
    ]
  },
  {
    "objectID": "docs/ts_analysis/dummy_file.html#code-with-annotations",
    "href": "docs/ts_analysis/dummy_file.html#code-with-annotations",
    "title": "presentation_dummy",
    "section": "2 Code with annotations",
    "text": "2 Code with annotations\n\n1library(tidyverse)\n2library(fpp3)\n\n3aus_production |&gt;\n  autoplot(Beer)\n\n\n1\n\nMeta-package for data-science analysis\n\n2\n\nMeta-package for time series forecasting\n\n3\n\nTime plot of Beer production",
    "crumbs": [
      "Models",
      "Univariate models",
      "Dummy file"
    ]
  },
  {
    "objectID": "docs/ts_analysis/dummy_pres.html#first-slide",
    "href": "docs/ts_analysis/dummy_pres.html#first-slide",
    "title": "presentation_dummy",
    "section": "1 First slide",
    "text": "1 First slide\nJust as a tutorial\n```{r}\n1 + 1\n```"
  },
  {
    "objectID": "docs/ts_analysis/dummy_pres.html#code-with-annotations",
    "href": "docs/ts_analysis/dummy_pres.html#code-with-annotations",
    "title": "presentation_dummy",
    "section": "2 Code with annotations",
    "text": "2 Code with annotations\n\n1library(tidyverse)\n2library(fpp3)\n\n3aus_production |&gt;\n  autoplot(Beer)\n\n\n1\n\nMeta-package for data-science analysis\n\n2\n\nMeta-package for time series forecasting\n\n3\n\nTime plot of Beer production"
  },
  {
    "objectID": "docs/forecasting/forecasting.html",
    "href": "docs/forecasting/forecasting.html",
    "title": "Forecasting workflow",
    "section": "",
    "text": "forecasting\n\n\nforecasting again\n\n\n\n\nfablemodeltime\n\n\n\nlibrary(tsibble)\nlibrary(feasts)\nlibrary(fable)\n\n\n\n\nlibrary(timetk)\nlibrary(modeltime)\n\n\n\n\n\nfablemodeltime\n\n\n\ndata_tsbl |&gt; \n  index_by() |&gt; \n  summarise()\n\n\n\n\ndata_tbl |&gt; \n  summarise_by_time()",
    "crumbs": [
      "Forecasting",
      "Forecasting principles"
    ]
  },
  {
    "objectID": "docs/forecasting/forecasting.html#h2",
    "href": "docs/forecasting/forecasting.html#h2",
    "title": "Forecasting workflow",
    "section": "",
    "text": "forecasting again",
    "crumbs": [
      "Forecasting",
      "Forecasting principles"
    ]
  },
  {
    "objectID": "docs/forecasting/forecasting.html#model",
    "href": "docs/forecasting/forecasting.html#model",
    "title": "Forecasting workflow",
    "section": "",
    "text": "fablemodeltime\n\n\n\nlibrary(tsibble)\nlibrary(feasts)\nlibrary(fable)\n\n\n\n\nlibrary(timetk)\nlibrary(modeltime)\n\n\n\n\n\nfablemodeltime\n\n\n\ndata_tsbl |&gt; \n  index_by() |&gt; \n  summarise()\n\n\n\n\ndata_tbl |&gt; \n  summarise_by_time()",
    "crumbs": [
      "Forecasting",
      "Forecasting principles"
    ]
  },
  {
    "objectID": "docs/forecasting/forecasting_pres.html#h2",
    "href": "docs/forecasting/forecasting_pres.html#h2",
    "title": "Forecasting workflow",
    "section": "1.1 H2",
    "text": "1.1 H2\nforecasting again"
  },
  {
    "objectID": "docs/forecasting/forecasting_pres.html#model",
    "href": "docs/forecasting/forecasting_pres.html#model",
    "title": "Forecasting workflow",
    "section": "1.2 model",
    "text": "1.2 model\n\nfablemodeltime\n\n\n\nlibrary(tsibble)\nlibrary(feasts)\nlibrary(fable)\n\n\n\n\nlibrary(timetk)\nlibrary(modeltime)\n\n\n\n\n\nfablemodeltime\n\n\n\ndata_tsbl |&gt; \n  index_by() |&gt; \n  summarise()\n\n\n\n\ndata_tbl |&gt; \n  summarise_by_time()"
  },
  {
    "objectID": "docs/models/ets.html",
    "href": "docs/models/ets.html",
    "title": "Exponential Smoothing",
    "section": "",
    "text": "ETS models.\n\n\nthere and back again.\n\n\n\n\n\n\n# Fill in the spot we created for a plot\noutput$phonePlot &lt;- renderPlot({\n  # Render a barplot\n})\n\n\n\n# Fill in the spot we created for a plot\noutput$phonePlot &lt;- renderPlot({\n  # Render a barplot\n  barplot(WorldPhones[,input$region]*1000, \n          main=input$region,\n          ylab=\"Number of Telephones\",\n          xlab=\"Year\")\n})",
    "crumbs": [
      "Models",
      "Univariate models",
      "Exponential Smoothing"
    ]
  },
  {
    "objectID": "docs/models/ets.html#h2-header",
    "href": "docs/models/ets.html#h2-header",
    "title": "Exponential Smoothing",
    "section": "",
    "text": "there and back again.",
    "crumbs": [
      "Models",
      "Univariate models",
      "Exponential Smoothing"
    ]
  },
  {
    "objectID": "docs/models/ets.html#section",
    "href": "docs/models/ets.html#section",
    "title": "Exponential Smoothing",
    "section": "",
    "text": "# Fill in the spot we created for a plot\noutput$phonePlot &lt;- renderPlot({\n  # Render a barplot\n})",
    "crumbs": [
      "Models",
      "Univariate models",
      "Exponential Smoothing"
    ]
  },
  {
    "objectID": "docs/models/ets.html#section-1",
    "href": "docs/models/ets.html#section-1",
    "title": "Exponential Smoothing",
    "section": "",
    "text": "# Fill in the spot we created for a plot\noutput$phonePlot &lt;- renderPlot({\n  # Render a barplot\n  barplot(WorldPhones[,input$region]*1000, \n          main=input$region,\n          ylab=\"Number of Telephones\",\n          xlab=\"Year\")\n})",
    "crumbs": [
      "Models",
      "Univariate models",
      "Exponential Smoothing"
    ]
  },
  {
    "objectID": "docs/models/ets_pres.html#h2-header",
    "href": "docs/models/ets_pres.html#h2-header",
    "title": "Exponential Smoothing",
    "section": "1.1 H2 header",
    "text": "1.1 H2 header\nthere and back again."
  },
  {
    "objectID": "docs/models/ets_pres.html#code-animation",
    "href": "docs/models/ets_pres.html#code-animation",
    "title": "Exponential Smoothing",
    "section": "1.2 Code animation",
    "text": "1.2 Code animation"
  },
  {
    "objectID": "docs/models/ets_pres.html#section",
    "href": "docs/models/ets_pres.html#section",
    "title": "Exponential Smoothing",
    "section": "1.3 ",
    "text": "1.3 \n# Fill in the spot we created for a plot\noutput$phonePlot &lt;- renderPlot({\n  # Render a barplot\n})"
  },
  {
    "objectID": "docs/models/ets_pres.html#section-1",
    "href": "docs/models/ets_pres.html#section-1",
    "title": "Exponential Smoothing",
    "section": "1.4 ",
    "text": "1.4 \n# Fill in the spot we created for a plot\noutput$phonePlot &lt;- renderPlot({\n  # Render a barplot\n  barplot(WorldPhones[,input$region]*1000, \n          main=input$region,\n          ylab=\"Number of Telephones\",\n          xlab=\"Year\")\n})"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Time Series Forecasting",
    "section": "",
    "text": "Website index.\n\n\n\n Back to top"
  },
  {
    "objectID": "docs/forecasting/forecasting_wf_pres.html#packages",
    "href": "docs/forecasting/forecasting_wf_pres.html#packages",
    "title": "The Forecasting Workflow using fable",
    "section": "0.1 Packages",
    "text": "0.1 Packages\nIt is recommended to load all the packages at the beginning of your file. We will be using the tidyverts ecosystem for the whole forecasting workflow.\n\nlibrary(tidyverse)\nlibrary(tsibble)\nlibrary(feasts)\nlibrary(fable)\nlibrary(tsibbledata)\nlibrary(fpp3)\nlibrary(plotly)\n\n\n\n\n\n\n\nWarning\n\n\nDo not load unnecesary packages into your environment. It could lead to conflicts between functions and unwanted results."
  },
  {
    "objectID": "docs/forecasting/forecasting_wf_pres.html#data",
    "href": "docs/forecasting/forecasting_wf_pres.html#data",
    "title": "The Forecasting Workflow using fable",
    "section": "1.1 Data",
    "text": "1.1 Data\nWe will work with the Real Gross Domestic Product (GDP) for Mexico. The data is downloaded from FRED. The time series id is NGDPRNSAXDCMXQ.\n1.1.1 Import data\n\ngdp &lt;- tidyquant::tq_get(\n  x    = \"NGDPRNSAXDCMXQ\",\n  get  = \"economic.data\",\n  from = \"1997-01-01\"\n)\n\ngdp\n\n\n  \n\n\n\n1.1.2 Wrangle data\nThere are some issues with our data:\n\nIt is loaded into a tibble object. We need to convert it to a tsibble.\n\n\n\n\n\n\n\nTip\n\n\nWe can use as_tsibble() to do so.\n\n\n\n\nOur data is quarterly, but it is loaded in a YYYY-MM-DD format. We need to change it to a YYYY QQ format.\n\n\n\n\n\n\n\nTip\n\n\nThere are some functions that help us achieve this, such as\n\nyearquarter()\nyearmonth()\nyearweek()\nyear()\n\ndepending on the time series’ period.\n\n\n\nWe will overwrite our data:\n\ngdp &lt;- gdp |&gt; \n  mutate(date = yearquarter(date)) |&gt; \n  as_tsibble(\n    index = date,\n    key   = symbol\n  )\n\ngdp\n\n\n  \n\n\n\n\n\n\n\n\n\nTip\n\n\n\nWe always need to specify the index argument, as it is our date variable.\nThe key argument is necessary whenever we have more than one time series in our data frame and is made up of one or more columns that uniquely identify each time series ."
  },
  {
    "objectID": "docs/forecasting/forecasting_wf_pres.html#traintest-split",
    "href": "docs/forecasting/forecasting_wf_pres.html#traintest-split",
    "title": "The Forecasting Workflow using fable",
    "section": "1.2 Train/Test Split",
    "text": "1.2 Train/Test Split\nWe will split our data in two sets: a training set, and a test set, in order to evaluate our forecasts’ accuracy.\n\ngdp_train &lt;- gdp |&gt; \n  filter_index(. ~ \"2020 Q4\")\n\ngdp_train\n\n\n  \n\n\n\n\n\n\n\n\n\nNote\n\n\nFor all our variables, it is strongly recommended to follow the same notation process, and write our code using snake_case. Here, we called our data gdp, therefore, all the following variables will be called starting with gdp_1, such as gdp_train for our training set.\n\n\n\nThis will make it very convenient when calling your variables. RStudio will display all the options starting with gdp_. We will usually use the following suffixes:\n\n_train: training set\n_fit: the mable (table of models)\n_aug: the augmented table with fitted values and residuals\n_dcmp: for the dable (decomposition table), containing the components and the seasonally adjusted series of a TS decomposition.\n_fc or _fcst: for the fable (forecasts table) that has our forecasts."
  },
  {
    "objectID": "docs/forecasting/forecasting_wf_pres.html#visualization-and-eda",
    "href": "docs/forecasting/forecasting_wf_pres.html#visualization-and-eda",
    "title": "The Forecasting Workflow using fable",
    "section": "1.3 Visualization and EDA",
    "text": "1.3 Visualization and EDA\nWhen performing time series analysis/forecasting, one of the first things to do is to create a time series plot.\n\np &lt;- gdp_train |&gt; \n  autoplot(price) +\n  labs(\n    title = \"Time series plot of the Real GDP for Mexico\",\n    y = \"GDP\"\n  )\n \nggplotly(p, dynamicTicks = TRUE) |&gt; \n  rangeslider()\n\n\n\n\n\n\n\n\nOur data exhibits an upward linear trend (with some economic cycles), and strong yearly seasonality.\n\n\n\nWe will explore it further with a season plot.\n\ngdp_train |&gt; \n  gg_season(price) |&gt; \n  ggplotly()\n\n\n\n\n\n1.3.1 TS Decomposition\n\ngdp_train |&gt; \n  model(stl = STL(price, robust = TRUE)) |&gt; \n  components() |&gt; \n  autoplot() |&gt; \n  ggplotly()\n\n\n\n\n\n\n\n\nThe STL decomposition shows that the variance of the seasonal component has been increasing. We could try using a log transformation to counter this.\n\n\n\n\ngdp_train |&gt; \n  autoplot(log(price)) +\n  ggtitle(\"Log of the Real GDP of Mexico\")\n\n\n\n\n\n\n\n\n\ngdp_train |&gt; \n  model(stl = STL(log(price) ~ season(window = \"periodic\"), robust = TRUE)) |&gt; \n  components() |&gt; \n  autoplot() |&gt; \n  ggplotly()"
  },
  {
    "objectID": "docs/forecasting/forecasting_wf_pres.html#model-specification",
    "href": "docs/forecasting/forecasting_wf_pres.html#model-specification",
    "title": "The Forecasting Workflow using fable",
    "section": "1.4 Model Specification",
    "text": "1.4 Model Specification\nWe will fit two models to our time series: Seasonal Naïve, and the Drift model. We will also use the log transformation.\n\ngdp_fit &lt;- gdp_train |&gt; \n  model(\n    snaive = SNAIVE(log(price)),\n    drift  = RW(log(price) ~ drift())\n  )\n\n\n\n\n\n\n\nBenchmark models\n\n\nWe have four different benchmark models that we’ll use to compare against the rest of the more complex models: - Mean (MEAN( &lt;.y&gt; )) - Naïve (NAIVE( &lt;.y&gt; )) - Seasonal Naïve (SNAIVE( &lt;.y&gt; )) - Drift (RW( &lt;.y&gt; ~ drift()))\nwhere &lt;.y&gt; is just a placeholder for the variable to model.\nChoose wisely which of these to use in each case, according to the exploratory analysis performed."
  },
  {
    "objectID": "docs/forecasting/forecasting_wf_pres.html#residuals-diagnostics",
    "href": "docs/forecasting/forecasting_wf_pres.html#residuals-diagnostics",
    "title": "The Forecasting Workflow using fable",
    "section": "1.5 Residuals Diagnostics",
    "text": "1.5 Residuals Diagnostics\n1.5.1 Visual analysis\n\ngdp_fit |&gt; \n  select(snaive) |&gt; \n  gg_tsresiduals() +\n  ggtitle(\"Residuals Diagnostics for the Seasonal Naïve Model\")\n\n\n\n\n\n\n\ngdp_fit |&gt; \n  select(drift) |&gt; \n  gg_tsresiduals() +\n  ggtitle(\"Residuals Diagnostics for the Drift Model\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\nHere we expect to see:\n\nA time series with no apparent patterns (no trend and/or seasonality), with a mean close to zero.\nIn the ACF, we’d expect no lags with significant autocorrelation.\nNormally distributed residuals.\n\n\n\n\n1.5.2 Portmanteau tests of autocorrelation\n\ngdp_fit |&gt; \n  augment() |&gt; \n  features(.innov, ljung_box, lag = 24, dof = 0)\n\n\n  \n\n\n\n\n\n\n\n\n\nResiduals interpretation\n\n\nBoth models produce sub optimal residuals:\n\nThe SNAIVE correctly detects the seasonality, however, its residuals are still autocorrelated. Moreover, the residuals are not normally distributed.\nThe drift model doesn’t account for the seasonality, and their distribution is a little bit skewed.\n\nHence, we will perform our forecasts using the bootstrapping method.\n\n\n\nWe can compute some error metrics on the training set using the accuracy() function:\n\ngdp_train_accu &lt;- accuracy(gdp_fit) |&gt; \n  arrange(MAPE)\ngdp_train_accu |&gt; \n  select(symbol:.type, MAPE, RMSE, MAE, MASE)\n\n\n  \n\n\n\n\n\n\n\n\n\nThe accuracy() function\n\n\nThe accuracy() function can be used to compute error metrics in the training data, or in the test set. What differs is the data that is given to it:\n\nFor the training metrics, you need to use the mable (the table of models, that we usually store in _fit).\nFor the forecasting error metrics, we need the fable (the forecasts table, usually stored as _fc or _fcst), and the complete set of data (both the training and test set together).\n\n\n\n\n\n\n\n\n\n\n\n\nFor this analysis, we are focusing on the MAPE1 metric. The drift model (2.45%) seems to have a better fit with the training set than the snaive model (3.08%).\n\n\n\nThe Mean Absolute Percentage Error is a percentage error metric widely used in professional environments.\nLet\n\\[\ne_t = y_t - \\hat{y}_t\n\\]\nbe the error or residual.\nThen the MAPE would be computed as\n\\[\nMAPE = \\frac{1}{T}\\sum_{t=1}^T|\\frac{e_t}{y_t}|\n\\]."
  },
  {
    "objectID": "docs/forecasting/forecasting_wf_pres.html#modeling-using-decomposition",
    "href": "docs/forecasting/forecasting_wf_pres.html#modeling-using-decomposition",
    "title": "The Forecasting Workflow using fable",
    "section": "1.6 Modeling using decomposition",
    "text": "1.6 Modeling using decomposition\nWe will perform a forecast using decomposition, to see if we can improve our results so far.\n\ngdp_fit_dcmp &lt;- gdp_train |&gt; \n      model(\n        stlf = decomposition_model(\n          STL(log(price) ~ season(window = \"periodic\"), robust = TRUE),\n          RW(season_adjust ~ drift())\n        )\n      )\n\ngdp_fit_dcmp\n\n\n  \n\n\n\n\n\n\n\n\n\nNote on decomposition_model()\n\n\nRemember, when using decomposition models, we need to do the following:\n\nSpecify what type of decomposition we want to use and customize it as needed.\nFit a model for the seasonally adjusted data; season_adjust.\nFit a model for the seasonal component. R uses a SNAIVE() model by default to model the seasonality. If you wish to model it using a different model, you have specify it.\n\n\nThe name of the seasonal component depends on the type of seasonality present in the time series. If it has a yearly seasonality, the component is called season_year. It could also be called season_week, season_day, and so on.\n\n\n\n\nWe can join this new model with the models we trained before. This way we can have them all in the same mable.\n\ngdp_fit &lt;- gdp_fit |&gt; \n  left_join(gdp_fit_dcmp)\n\nJoining with `by = join_by(symbol)`\n\n\n1.6.1 Residuals diagnostics\n\ngdp_fit |&gt; \n  accuracy() |&gt; \n  select(symbol:.type, MAPE, RMSE, MAE, MASE) |&gt; \n  arrange(MAPE)\n\n\n  \n\n\n\n\ngdp_fit |&gt; \n  select(stlf) |&gt; \n  gg_tsresiduals()\n\n\n\n\n\n\n\n\n\ngdp_fit |&gt; \n  augment() |&gt; \n  features(.innov, ljung_box)\n\n\n  \n\n\n\n\n\n\nThe MAPE seems to improve with this decomposition model. Also, the residual diagnostics do not show any seasonality present in them. However, the residuals are still autocorrelated, as the Ljung-Box test suggests."
  },
  {
    "objectID": "docs/forecasting/forecasting_wf_pres.html#forecasting-on-the-test-set",
    "href": "docs/forecasting/forecasting_wf_pres.html#forecasting-on-the-test-set",
    "title": "The Forecasting Workflow using fable",
    "section": "1.7 Forecasting on the test set",
    "text": "1.7 Forecasting on the test set\nOnce we have our models, we can produce forecasts. We will forecast our test data and check our forecasts’ performance.\n\ngdp_fc &lt;- gdp_fit |&gt; \n  forecast(h = 6) \n\ngdp_fc\n\n\n  \n\n\n\n\ngdp_fc |&gt; \n  autoplot(gdp) +\n  facet_wrap(~.model, ncol = 1)\n\n\n\n\n\n\n\ngdp_fc |&gt; \n  filter(.model == \"stlf\") |&gt; \n  autoplot(gdp)\n\n\n\n\n\n\n\n\nWe now estimate the forecast errors:\n\ngdp_fc |&gt; \n  accuracy(gdp) |&gt; \n  select(.model:.type, MAPE, RMSE, MAE, MASE) |&gt; \n  arrange(MAPE)"
  },
  {
    "objectID": "docs/forecasting/forecasting_wf_pres.html#forecasting-the-future",
    "href": "docs/forecasting/forecasting_wf_pres.html#forecasting-the-future",
    "title": "The Forecasting Workflow using fable",
    "section": "1.8 Forecasting the future",
    "text": "1.8 Forecasting the future\nWe now refit our model using the whole dataset. We will only model the STL decomposition model, because the other two didn’t get a strong fit.\n\ngdp_fit2 &lt;- gdp |&gt; \n  model(\n    stlf = decomposition_model(\n          STL(log(price) ~ season(window = \"periodic\"), robust = TRUE),\n          RW(season_adjust ~ drift())\n        )\n  )\ngdp_fit2\n\n\n  \n\n\n\n\ngdp_fc_fut &lt;- gdp_fit2 |&gt; \n  forecast(h = \"3 years\")\ngdp_fc_fut\n\n\n  \n\n\ngdp_fc_fut |&gt; \n  autoplot(gdp)\n\n\n\n\n\n\n\n\n\n# save(gdp_fc_fut, file = \"equipo1.RData\")"
  },
  {
    "objectID": "docs/forecasting/forecasting_workflow.html#packages",
    "href": "docs/forecasting/forecasting_workflow.html#packages",
    "title": "The Forecasting Workflow using fable",
    "section": "0.1 Packages",
    "text": "0.1 Packages\nIt is recommended to load all the packages at the beginning of your file. We will be using the tidyverts ecosystem for the whole forecasting workflow.\n\nlibrary(tidyverse)\nlibrary(tsibble)\nlibrary(feasts)\nlibrary(fable)\nlibrary(tsibbledata)\nlibrary(fpp3)\nlibrary(plotly)\n\n\n\n\n\n\n\nWarning\n\n\n\nDo not load unnecesary packages into your environment. It could lead to conflicts between functions and unwanted results.",
    "crumbs": [
      "Forecasting",
      "The Forecasting Workflow"
    ]
  },
  {
    "objectID": "docs/forecasting/forecasting_workflow.html#data",
    "href": "docs/forecasting/forecasting_workflow.html#data",
    "title": "The Forecasting Workflow using fable",
    "section": "1.1 Data",
    "text": "1.1 Data\nWe will work with the Real Gross Domestic Product (GDP) for Mexico. The data is downloaded from FRED. The time series id is NGDPRNSAXDCMXQ.\n\n1.1.1 Import data\n\ngdp &lt;- tidyquant::tq_get(\n  x    = \"NGDPRNSAXDCMXQ\",\n  get  = \"economic.data\",\n  from = \"1997-01-01\"\n)\n\ngdp\n\n\n  \n\n\n\n\n\n1.1.2 Wrangle data\nThere are some issues with our data:\n\nIt is loaded into a tibble object. We need to convert it to a tsibble.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nWe can use as_tsibble() to do so.\n\n\n\n\nOur data is quarterly, but it is loaded in a YYYY-MM-DD format. We need to change it to a YYYY QQ format.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nThere are some functions that help us achieve this, such as\n\nyearquarter()\nyearmonth()\nyearweek()\nyear()\n\ndepending on the time series’ period.\n\n\n\nWe will overwrite our data:\n\ngdp &lt;- gdp |&gt; \n  mutate(date = yearquarter(date)) |&gt; \n  as_tsibble(\n    index = date,\n    key   = symbol\n  )\n\ngdp\n\n\n  \n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nWe always need to specify the index argument, as it is our date variable.\nThe key argument is necessary whenever we have more than one time series in our data frame and is made up of one or more columns that uniquely identify each time series .",
    "crumbs": [
      "Forecasting",
      "The Forecasting Workflow"
    ]
  },
  {
    "objectID": "docs/forecasting/forecasting_workflow.html#traintest-split",
    "href": "docs/forecasting/forecasting_workflow.html#traintest-split",
    "title": "The Forecasting Workflow using fable",
    "section": "1.2 Train/Test Split",
    "text": "1.2 Train/Test Split\nWe will split our data in two sets: a training set, and a test set, in order to evaluate our forecasts’ accuracy.\n\ngdp_train &lt;- gdp |&gt; \n  filter_index(. ~ \"2020 Q4\")\n\ngdp_train\n\n\n  \n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFor all our variables, it is strongly recommended to follow the same notation process, and write our code using snake_case. Here, we called our data gdp, therefore, all the following variables will be called starting with gdp_1, such as gdp_train for our training set.",
    "crumbs": [
      "Forecasting",
      "The Forecasting Workflow"
    ]
  },
  {
    "objectID": "docs/forecasting/forecasting_workflow.html#visualization-and-eda",
    "href": "docs/forecasting/forecasting_workflow.html#visualization-and-eda",
    "title": "The Forecasting Workflow using fable",
    "section": "1.3 Visualization and EDA",
    "text": "1.3 Visualization and EDA\nWhen performing time series analysis/forecasting, one of the first things to do is to create a time series plot.\n\np &lt;- gdp_train |&gt; \n  autoplot(price) +\n  labs(\n    title = \"Time series plot of the Real GDP for Mexico\",\n    y = \"GDP\"\n  )\n \nggplotly(p, dynamicTicks = TRUE) |&gt; \n  rangeslider()\n\n\n\n\n\n\n\n\n\n\n\nOur data exhibits an upward linear trend (with some economic cycles), and strong yearly seasonality.\n\n\n\nWe will explore it further with a season plot.\n\ngdp_train |&gt; \n  gg_season(price) |&gt; \n  ggplotly()\n\n\n\n\n\n\n1.3.1 TS Decomposition\n\ngdp_train |&gt; \n  model(stl = STL(price, robust = TRUE)) |&gt; \n  components() |&gt; \n  autoplot() |&gt; \n  ggplotly()\n\n\n\n\n\n\n\n\n\n\n\nThe STL decomposition shows that the variance of the seasonal component has been increasing. We could try using a log transformation to counter this.\n\n\n\n\ngdp_train |&gt; \n  autoplot(log(price)) +\n  ggtitle(\"Log of the Real GDP of Mexico\")\n\n\n\n\n\n\n\n\n\ngdp_train |&gt; \n  model(stl = STL(log(price) ~ season(window = \"periodic\"), robust = TRUE)) |&gt; \n  components() |&gt; \n  autoplot() |&gt; \n  ggplotly()",
    "crumbs": [
      "Forecasting",
      "The Forecasting Workflow"
    ]
  },
  {
    "objectID": "docs/forecasting/forecasting_workflow.html#model-specification",
    "href": "docs/forecasting/forecasting_workflow.html#model-specification",
    "title": "The Forecasting Workflow using fable",
    "section": "1.4 Model Specification",
    "text": "1.4 Model Specification\nWe will fit two models to our time series: Seasonal Naïve, and the Drift model. We will also use the log transformation.\n\ngdp_fit &lt;- gdp_train |&gt; \n  model(\n    snaive = SNAIVE(log(price)),\n    drift  = RW(log(price) ~ drift())\n  )\n\n\n\n\n\n\n\nBenchmark models\n\n\n\n\n\nWe have four different benchmark models that we’ll use to compare against the rest of the more complex models: - Mean (MEAN( &lt;.y&gt; )) - Naïve (NAIVE( &lt;.y&gt; )) - Seasonal Naïve (SNAIVE( &lt;.y&gt; )) - Drift (RW( &lt;.y&gt; ~ drift()))\nwhere &lt;.y&gt; is just a placeholder for the variable to model.\nChoose wisely which of these to use in each case, according to the exploratory analysis performed.",
    "crumbs": [
      "Forecasting",
      "The Forecasting Workflow"
    ]
  },
  {
    "objectID": "docs/forecasting/forecasting_workflow.html#residuals-diagnostics",
    "href": "docs/forecasting/forecasting_workflow.html#residuals-diagnostics",
    "title": "The Forecasting Workflow using fable",
    "section": "1.5 Residuals Diagnostics",
    "text": "1.5 Residuals Diagnostics\n\n1.5.1 Visual analysis\n\ngdp_fit |&gt; \n  select(snaive) |&gt; \n  gg_tsresiduals() +\n  ggtitle(\"Residuals Diagnostics for the Seasonal Naïve Model\")\n\n\n\n\n\n\n\ngdp_fit |&gt; \n  select(drift) |&gt; \n  gg_tsresiduals() +\n  ggtitle(\"Residuals Diagnostics for the Drift Model\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nHere we expect to see:\n\nA time series with no apparent patterns (no trend and/or seasonality), with a mean close to zero.\nIn the ACF, we’d expect no lags with significant autocorrelation.\nNormally distributed residuals.\n\n\n\n\n\n\n1.5.2 Portmanteau tests of autocorrelation\n\ngdp_fit |&gt; \n  augment() |&gt; \n  features(.innov, ljung_box, lag = 24, dof = 0)\n\n\n  \n\n\n\n\n\n\n\n\n\nResiduals interpretation\n\n\n\nBoth models produce sub optimal residuals:\n\nThe SNAIVE correctly detects the seasonality, however, its residuals are still autocorrelated. Moreover, the residuals are not normally distributed.\nThe drift model doesn’t account for the seasonality, and their distribution is a little bit skewed.\n\nHence, we will perform our forecasts using the bootstrapping method.\n\n\nWe can compute some error metrics on the training set using the accuracy() function:\n\ngdp_train_accu &lt;- accuracy(gdp_fit) |&gt; \n  arrange(MAPE)\ngdp_train_accu |&gt; \n  select(symbol:.type, MAPE, RMSE, MAE, MASE)\n\n\n  \n\n\n\n\n\n\n\n\n\nThe accuracy() function\n\n\n\n\n\nThe accuracy() function can be used to compute error metrics in the training data, or in the test set. What differs is the data that is given to it:\n\nFor the training metrics, you need to use the mable (the table of models, that we usually store in _fit).\nFor the forecasting error metrics, we need the fable (the forecasts table, usually stored as _fc or _fcst), and the complete set of data (both the training and test set together).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor this analysis, we are focusing on the MAPE2 metric. The drift model (2.45%) seems to have a better fit with the training set than the snaive model (3.08%).",
    "crumbs": [
      "Forecasting",
      "The Forecasting Workflow"
    ]
  },
  {
    "objectID": "docs/forecasting/forecasting_workflow.html#modeling-using-decomposition",
    "href": "docs/forecasting/forecasting_workflow.html#modeling-using-decomposition",
    "title": "The Forecasting Workflow using fable",
    "section": "1.6 Modeling using decomposition",
    "text": "1.6 Modeling using decomposition\nWe will perform a forecast using decomposition, to see if we can improve our results so far.\n\ngdp_fit_dcmp &lt;- gdp_train |&gt; \n      model(\n        stlf = decomposition_model(\n          STL(log(price) ~ season(window = \"periodic\"), robust = TRUE),\n          RW(season_adjust ~ drift())\n        )\n      )\n\ngdp_fit_dcmp\n\n\n  \n\n\n\n\n\n\n\n\n\nNote on decomposition_model()\n\n\n\n\n\nRemember, when using decomposition models, we need to do the following:\n\nSpecify what type of decomposition we want to use and customize it as needed.\nFit a model for the seasonally adjusted data; season_adjust.\nFit a model for the seasonal component. R uses a SNAIVE() model by default to model the seasonality. If you wish to model it using a different model, you have specify it.\n\n\nThe name of the seasonal component depends on the type of seasonality present in the time series. If it has a yearly seasonality, the component is called season_year. It could also be called season_week, season_day, and so on.\n\n\n\n\nWe can join this new model with the models we trained before. This way we can have them all in the same mable.\n\ngdp_fit &lt;- gdp_fit |&gt; \n  left_join(gdp_fit_dcmp)\n\nJoining with `by = join_by(symbol)`\n\n\n\n1.6.1 Residuals diagnostics\n\ngdp_fit |&gt; \n  accuracy() |&gt; \n  select(symbol:.type, MAPE, RMSE, MAE, MASE) |&gt; \n  arrange(MAPE)\n\n\n  \n\n\n\n\ngdp_fit |&gt; \n  select(stlf) |&gt; \n  gg_tsresiduals()\n\n\n\n\n\n\n\n\n\ngdp_fit |&gt; \n  augment() |&gt; \n  features(.innov, ljung_box)\n\n\n  \n\n\n\n\n\n\n\n\n\nThe MAPE seems to improve with this decomposition model. Also, the residual diagnostics do not show any seasonality present in them. However, the residuals are still autocorrelated, as the Ljung-Box test suggests.",
    "crumbs": [
      "Forecasting",
      "The Forecasting Workflow"
    ]
  },
  {
    "objectID": "docs/forecasting/forecasting_workflow.html#forecasting-on-the-test-set",
    "href": "docs/forecasting/forecasting_workflow.html#forecasting-on-the-test-set",
    "title": "The Forecasting Workflow using fable",
    "section": "1.7 Forecasting on the test set",
    "text": "1.7 Forecasting on the test set\nOnce we have our models, we can produce forecasts. We will forecast our test data and check our forecasts’ performance.\n\ngdp_fc &lt;- gdp_fit |&gt; \n  forecast(h = 6) \n\ngdp_fc\n\n\n  \n\n\n\n\ngdp_fc |&gt; \n  autoplot(gdp) +\n  facet_wrap(~.model, ncol = 1)\n\n\n\n\n\n\n\ngdp_fc |&gt; \n  filter(.model == \"stlf\") |&gt; \n  autoplot(gdp)\n\n\n\n\n\n\n\n\nWe now estimate the forecast errors:\n\ngdp_fc |&gt; \n  accuracy(gdp) |&gt; \n  select(.model:.type, MAPE, RMSE, MAE, MASE) |&gt; \n  arrange(MAPE)",
    "crumbs": [
      "Forecasting",
      "The Forecasting Workflow"
    ]
  },
  {
    "objectID": "docs/forecasting/forecasting_workflow.html#forecasting-the-future",
    "href": "docs/forecasting/forecasting_workflow.html#forecasting-the-future",
    "title": "The Forecasting Workflow using fable",
    "section": "1.8 Forecasting the future",
    "text": "1.8 Forecasting the future\nWe now refit our model using the whole dataset. We will only model the STL decomposition model, because the other two didn’t get a strong fit.\n\ngdp_fit2 &lt;- gdp |&gt; \n  model(\n    stlf = decomposition_model(\n          STL(log(price) ~ season(window = \"periodic\"), robust = TRUE),\n          RW(season_adjust ~ drift())\n        )\n  )\ngdp_fit2\n\n\n  \n\n\n\n\ngdp_fc_fut &lt;- gdp_fit2 |&gt; \n  forecast(h = \"3 years\")\ngdp_fc_fut\n\n\n  \n\n\ngdp_fc_fut |&gt; \n  autoplot(gdp)\n\n\n\n\n\n\n\n\n\n# save(gdp_fc_fut, file = \"equipo1.RData\")",
    "crumbs": [
      "Forecasting",
      "The Forecasting Workflow"
    ]
  },
  {
    "objectID": "docs/forecasting/forecasting_workflow.html#footnotes",
    "href": "docs/forecasting/forecasting_workflow.html#footnotes",
    "title": "The Forecasting Workflow using fable",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis will make it very convenient when calling your variables. RStudio will display all the options starting with gdp_. We will usually use the following suffixes:\n\n_train: training set\n_fit: the mable (table of models)\n_aug: the augmented table with fitted values and residuals\n_dcmp: for the dable (decomposition table), containing the components and the seasonally adjusted series of a TS decomposition.\n_fc or _fcst: for the fable (forecasts table) that has our forecasts. \n\n↩︎\nThe Mean Absolute Percentage Error is a percentage error metric widely used in professional environments.\nLet\n\\[\ne_t = y_t - \\hat{y}_t\n\\]\nbe the error or residual.\nThen the MAPE would be computed as\n\\[\nMAPE = \\frac{1}{T}\\sum_{t=1}^T|\\frac{e_t}{y_t}|\n\\].\n\n\n\n\n\n↩︎",
    "crumbs": [
      "Forecasting",
      "The Forecasting Workflow"
    ]
  },
  {
    "objectID": "docs/forecasting/intro/intro_pres.html#is-this-a-time-series",
    "href": "docs/forecasting/intro/intro_pres.html#is-this-a-time-series",
    "title": "Time Series Forecasting",
    "section": "1.1 Is this a time series?",
    "text": "1.1 Is this a time series?\n\n\n\n\n\n\n\nIf we focus solely on the regular plot, we wouldn’t have any time series. However, when we map each variable through time, we now have multiple time series: one for each country regarding life exp., GDP per capita, and population."
  },
  {
    "objectID": "docs/forecasting/intro/intro_pres.html#stocks",
    "href": "docs/forecasting/intro/intro_pres.html#stocks",
    "title": "Time Series Forecasting",
    "section": "2.1 Stocks",
    "text": "2.1 Stocks\n\n\n\n\n\n\n\n\n\n\n\n\n\nStocks, FX, … are all time series"
  },
  {
    "objectID": "docs/forecasting/intro/intro_pres.html#cryptos",
    "href": "docs/forecasting/intro/intro_pres.html#cryptos",
    "title": "Time Series Forecasting",
    "section": "2.2 Cryptos",
    "text": "2.2 Cryptos\n\nAny variable that is measured through time is a time series."
  },
  {
    "objectID": "docs/forecasting/intro/intro_pres.html#section",
    "href": "docs/forecasting/intro/intro_pres.html#section",
    "title": "Time Series Forecasting",
    "section": "3.1 ",
    "text": "3.1 \n\n\n\n\n\nflowchart LR\n    A(There are two types of Data Scientists)"
  },
  {
    "objectID": "docs/forecasting/intro/intro_pres.html#section-1",
    "href": "docs/forecasting/intro/intro_pres.html#section-1",
    "title": "Time Series Forecasting",
    "section": "3.2 ",
    "text": "3.2 \n\n\n\n\n\nflowchart LR\n    A(There are two types of Data Scientists)\n    A--&gt;B(Those who can't predict the future)"
  },
  {
    "objectID": "docs/forecasting/intro/intro_pres.html#section-2",
    "href": "docs/forecasting/intro/intro_pres.html#section-2",
    "title": "Time Series Forecasting",
    "section": "3.3 ",
    "text": "3.3 \n\n\n\n\n\nflowchart LR\n    A(There are two types of Data Scientists)\n    A--&gt;B(Those who can't predict the future)\n    A--&gt;C(Those who don't know that they can't predict the future)"
  },
  {
    "objectID": "docs/forecasting/intro/intro_pres.html#section-3",
    "href": "docs/forecasting/intro/intro_pres.html#section-3",
    "title": "Time Series Forecasting",
    "section": "3.4 ",
    "text": "3.4"
  },
  {
    "objectID": "docs/forecasting/intro/intro_pres.html#section-4",
    "href": "docs/forecasting/intro/intro_pres.html#section-4",
    "title": "Time Series Forecasting",
    "section": "3.5 ",
    "text": "3.5 \n\nDr. Strange didn’t have the Time stone. He was using a high-tech gamer PC to run millions of simulations."
  },
  {
    "objectID": "docs/forecasting/intro/intro_pres.html#eclipses",
    "href": "docs/forecasting/intro/intro_pres.html#eclipses",
    "title": "Time Series Forecasting",
    "section": "4.1 Eclipses",
    "text": "4.1 Eclipses"
  },
  {
    "objectID": "docs/forecasting/intro/intro_pres.html#section-5",
    "href": "docs/forecasting/intro/intro_pres.html#section-5",
    "title": "Time Series Forecasting",
    "section": "4.2 ",
    "text": "4.2 \n\n\n\n\n\nIt’s not so easy to predict stock prices"
  },
  {
    "objectID": "docs/forecasting/intro/intro_pres.html#beer-production-forecasts",
    "href": "docs/forecasting/intro/intro_pres.html#beer-production-forecasts",
    "title": "Time Series Forecasting",
    "section": "4.3 Beer Production Forecasts",
    "text": "4.3 Beer Production Forecasts\n\n\n\n\n\n\n\nCan you observe any strange patterns?"
  },
  {
    "objectID": "docs/forecasting/intro/intro_pres.html#electricity-demand",
    "href": "docs/forecasting/intro/intro_pres.html#electricity-demand",
    "title": "Time Series Forecasting",
    "section": "4.4 Electricity Demand",
    "text": "4.4 Electricity Demand"
  },
  {
    "objectID": "docs/forecasting/intro/intro_pres.html#employment",
    "href": "docs/forecasting/intro/intro_pres.html#employment",
    "title": "Time Series Forecasting",
    "section": "4.5 Employment",
    "text": "4.5 Employment\n\n\n\n\n\nUS Retail Employment"
  },
  {
    "objectID": "docs/forecasting/intro/intro.html",
    "href": "docs/forecasting/intro/intro.html",
    "title": "Time Series Forecasting",
    "section": "",
    "text": "If we focus solely on the regular plot, we wouldn’t have any time series. However, when we map each variable through time, we now have multiple time series: one for each country regarding life exp., GDP per capita, and population.",
    "crumbs": [
      "Forecasting",
      "Introduction"
    ]
  },
  {
    "objectID": "docs/forecasting/intro/intro.html#is-this-a-time-series",
    "href": "docs/forecasting/intro/intro.html#is-this-a-time-series",
    "title": "Time Series Forecasting",
    "section": "",
    "text": "If we focus solely on the regular plot, we wouldn’t have any time series. However, when we map each variable through time, we now have multiple time series: one for each country regarding life exp., GDP per capita, and population.",
    "crumbs": [
      "Forecasting",
      "Introduction"
    ]
  },
  {
    "objectID": "docs/forecasting/intro/intro.html#stocks",
    "href": "docs/forecasting/intro/intro.html#stocks",
    "title": "Time Series Forecasting",
    "section": "2.1 Stocks",
    "text": "2.1 Stocks\n\n\n\n\n\n\n\n\n\n\n\n\n\nStocks, FX, … are all time series",
    "crumbs": [
      "Forecasting",
      "Introduction"
    ]
  },
  {
    "objectID": "docs/forecasting/intro/intro.html#cryptos",
    "href": "docs/forecasting/intro/intro.html#cryptos",
    "title": "Time Series Forecasting",
    "section": "2.2 Cryptos",
    "text": "2.2 Cryptos\n\n\n\nCrypto currencies are also time series\n\n\n\nAny variable that is measured through time is a time series.",
    "crumbs": [
      "Forecasting",
      "Introduction"
    ]
  },
  {
    "objectID": "docs/forecasting/intro/intro.html#section-2",
    "href": "docs/forecasting/intro/intro.html#section-2",
    "title": "Time Series Forecasting",
    "section": "3.1 ",
    "text": "3.1 \n\n\n\n\n\nflowchart LR\n    A(There are two types of Data Scientists)\n    A--&gt;B(Those who can't predict the future)\n    A--&gt;C(Those who don't know that they can't predict the future)",
    "crumbs": [
      "Forecasting",
      "Introduction"
    ]
  },
  {
    "objectID": "docs/forecasting/intro/intro.html#section-3",
    "href": "docs/forecasting/intro/intro.html#section-3",
    "title": "Time Series Forecasting",
    "section": "3.2 ",
    "text": "3.2 \n\n\n\nWhat was Dr. Strange doing here?",
    "crumbs": [
      "Forecasting",
      "Introduction"
    ]
  },
  {
    "objectID": "docs/forecasting/intro/intro.html#section-4",
    "href": "docs/forecasting/intro/intro.html#section-4",
    "title": "Time Series Forecasting",
    "section": "3.3 ",
    "text": "3.3 \n\nDr. Strange didn’t have the Time stone. He was using a high-tech gamer PC to run millions of simulations.",
    "crumbs": [
      "Forecasting",
      "Introduction"
    ]
  },
  {
    "objectID": "docs/forecasting/intro/intro.html#eclipses",
    "href": "docs/forecasting/intro/intro.html#eclipses",
    "title": "Time Series Forecasting",
    "section": "4.1 Eclipses",
    "text": "4.1 Eclipses\n\n\n\nWe can predict eclipses with complete certainty",
    "crumbs": [
      "Forecasting",
      "Introduction"
    ]
  },
  {
    "objectID": "docs/forecasting/intro/intro.html#section-5",
    "href": "docs/forecasting/intro/intro.html#section-5",
    "title": "Time Series Forecasting",
    "section": "4.2 ",
    "text": "4.2 \n\n\n\n\n\nIt’s not so easy to predict stock prices",
    "crumbs": [
      "Forecasting",
      "Introduction"
    ]
  },
  {
    "objectID": "docs/forecasting/intro/intro.html#beer-production-forecasts",
    "href": "docs/forecasting/intro/intro.html#beer-production-forecasts",
    "title": "Time Series Forecasting",
    "section": "4.3 Beer Production Forecasts",
    "text": "4.3 Beer Production Forecasts\n\n\n\n\n\n\n\nCan you observe any strange patterns?",
    "crumbs": [
      "Forecasting",
      "Introduction"
    ]
  },
  {
    "objectID": "docs/forecasting/intro/intro.html#electricity-demand",
    "href": "docs/forecasting/intro/intro.html#electricity-demand",
    "title": "Time Series Forecasting",
    "section": "4.4 Electricity Demand",
    "text": "4.4 Electricity Demand",
    "crumbs": [
      "Forecasting",
      "Introduction"
    ]
  },
  {
    "objectID": "docs/forecasting/intro/intro.html#employment",
    "href": "docs/forecasting/intro/intro.html#employment",
    "title": "Time Series Forecasting",
    "section": "4.5 Employment",
    "text": "4.5 Employment\n\n\n\n\n\nUS Retail Employment",
    "crumbs": [
      "Forecasting",
      "Introduction"
    ]
  }
]