[
  {
    "objectID": "docs/modules/module_1/01_intro/intro.html",
    "href": "docs/modules/module_1/01_intro/intro.html",
    "title": "Time Series Forecasting",
    "section": "",
    "text": "If we focus solely on the regular plot, we wouldn’t have any time series. However, when we map each variable through time, we now have multiple time series: one for each country regarding life exp., GDP per capita, and population.",
    "crumbs": [
      "Modules",
      "Forecasting models based on decomposition methods",
      "Introduction"
    ]
  },
  {
    "objectID": "docs/modules/module_1/01_intro/intro.html#is-this-a-time-series",
    "href": "docs/modules/module_1/01_intro/intro.html#is-this-a-time-series",
    "title": "Time Series Forecasting",
    "section": "",
    "text": "If we focus solely on the regular plot, we wouldn’t have any time series. However, when we map each variable through time, we now have multiple time series: one for each country regarding life exp., GDP per capita, and population.",
    "crumbs": [
      "Modules",
      "Forecasting models based on decomposition methods",
      "Introduction"
    ]
  },
  {
    "objectID": "docs/modules/module_1/01_intro/intro.html#stocks",
    "href": "docs/modules/module_1/01_intro/intro.html#stocks",
    "title": "Time Series Forecasting",
    "section": "Stocks",
    "text": "Stocks\n\n\n\n\n\n\n\n\n\n\n\n\n\nStocks, FX, … are all time series",
    "crumbs": [
      "Modules",
      "Forecasting models based on decomposition methods",
      "Introduction"
    ]
  },
  {
    "objectID": "docs/modules/module_1/01_intro/intro.html#cryptos",
    "href": "docs/modules/module_1/01_intro/intro.html#cryptos",
    "title": "Time Series Forecasting",
    "section": "Cryptos",
    "text": "Cryptos\n\n\n\nCrypto currencies are also time series\n\n\n\nAny variable that is measured through time is a time series.",
    "crumbs": [
      "Modules",
      "Forecasting models based on decomposition methods",
      "Introduction"
    ]
  },
  {
    "objectID": "docs/modules/module_1/01_intro/intro.html#section-2",
    "href": "docs/modules/module_1/01_intro/intro.html#section-2",
    "title": "Time Series Forecasting",
    "section": "",
    "text": "flowchart LR\n    A(There are two types of Data Scientists)\n    A--&gt;B(Those who can't predict the future)\n    A--&gt;C(Those who don't know that they can't predict the future)\n\n\n\n\n\n\n\nNo one, except for sorcerers and wizards, can predict the future.",
    "crumbs": [
      "Modules",
      "Forecasting models based on decomposition methods",
      "Introduction"
    ]
  },
  {
    "objectID": "docs/modules/module_1/01_intro/intro.html#section-3",
    "href": "docs/modules/module_1/01_intro/intro.html#section-3",
    "title": "Time Series Forecasting",
    "section": "",
    "text": "What was Dr. Strange doing here?",
    "crumbs": [
      "Modules",
      "Forecasting models based on decomposition methods",
      "Introduction"
    ]
  },
  {
    "objectID": "docs/modules/module_1/01_intro/intro.html#section-4",
    "href": "docs/modules/module_1/01_intro/intro.html#section-4",
    "title": "Time Series Forecasting",
    "section": "",
    "text": "Dr. Strange didn’t have the Time stone. He was using a high-tech gamer PC to run millions of simulations.",
    "crumbs": [
      "Modules",
      "Forecasting models based on decomposition methods",
      "Introduction"
    ]
  },
  {
    "objectID": "docs/modules/module_1/01_intro/intro.html#eclipses",
    "href": "docs/modules/module_1/01_intro/intro.html#eclipses",
    "title": "Time Series Forecasting",
    "section": "Eclipses",
    "text": "Eclipses\n\n\nWe can predict eclipses with complete certainty.",
    "crumbs": [
      "Modules",
      "Forecasting models based on decomposition methods",
      "Introduction"
    ]
  },
  {
    "objectID": "docs/modules/module_1/01_intro/intro.html#section-5",
    "href": "docs/modules/module_1/01_intro/intro.html#section-5",
    "title": "Time Series Forecasting",
    "section": "",
    "text": "It’s not so easy to predict stock prices\n\n\n\n\n\nOther variables can’t be predicted that easily. What does it depend on?",
    "crumbs": [
      "Modules",
      "Forecasting models based on decomposition methods",
      "Introduction"
    ]
  },
  {
    "objectID": "docs/modules/module_1/01_intro/intro.html#beer-production-forecasts",
    "href": "docs/modules/module_1/01_intro/intro.html#beer-production-forecasts",
    "title": "Time Series Forecasting",
    "section": "Beer Production Forecasts",
    "text": "Beer Production Forecasts\n\n\n\n\n\n\n\nCan you observe any strange patterns?",
    "crumbs": [
      "Modules",
      "Forecasting models based on decomposition methods",
      "Introduction"
    ]
  },
  {
    "objectID": "docs/modules/module_1/01_intro/intro.html#electricity-demand",
    "href": "docs/modules/module_1/01_intro/intro.html#electricity-demand",
    "title": "Time Series Forecasting",
    "section": "Electricity Demand",
    "text": "Electricity Demand",
    "crumbs": [
      "Modules",
      "Forecasting models based on decomposition methods",
      "Introduction"
    ]
  },
  {
    "objectID": "docs/modules/module_1/01_intro/intro.html#employment",
    "href": "docs/modules/module_1/01_intro/intro.html#employment",
    "title": "Time Series Forecasting",
    "section": "Employment",
    "text": "Employment\n\n\n\n\n\nUS Retail Employment",
    "crumbs": [
      "Modules",
      "Forecasting models based on decomposition methods",
      "Introduction"
    ]
  },
  {
    "objectID": "docs/modules/module_1/01_intro/intro_pres.html#is-this-a-time-series",
    "href": "docs/modules/module_1/01_intro/intro_pres.html#is-this-a-time-series",
    "title": "Time Series Forecasting",
    "section": "Is this a time series?",
    "text": "Is this a time series?\n\n\n\n\n\n\n\nIf we focus solely on the regular plot, we wouldn’t have any time series. However, when we map each variable through time, we now have multiple time series: one for each country regarding life exp., GDP per capita, and population."
  },
  {
    "objectID": "docs/modules/module_1/01_intro/intro_pres.html#stocks",
    "href": "docs/modules/module_1/01_intro/intro_pres.html#stocks",
    "title": "Time Series Forecasting",
    "section": "Stocks",
    "text": "Stocks\n\n\n\n\n\n\n\n\n\n\n\n\n\nStocks, FX, … are all time series"
  },
  {
    "objectID": "docs/modules/module_1/01_intro/intro_pres.html#cryptos",
    "href": "docs/modules/module_1/01_intro/intro_pres.html#cryptos",
    "title": "Time Series Forecasting",
    "section": "Cryptos",
    "text": "Cryptos\n\nAny variable that is measured through time is a time series."
  },
  {
    "objectID": "docs/modules/module_1/01_intro/intro_pres.html#section",
    "href": "docs/modules/module_1/01_intro/intro_pres.html#section",
    "title": "Time Series Forecasting",
    "section": "",
    "text": "flowchart LR\n    A(There are two types of Data Scientists)"
  },
  {
    "objectID": "docs/modules/module_1/01_intro/intro_pres.html#section-1",
    "href": "docs/modules/module_1/01_intro/intro_pres.html#section-1",
    "title": "Time Series Forecasting",
    "section": "",
    "text": "flowchart LR\n    A(There are two types of Data Scientists)\n    A--&gt;B(Those who can't predict the future)"
  },
  {
    "objectID": "docs/modules/module_1/01_intro/intro_pres.html#section-2",
    "href": "docs/modules/module_1/01_intro/intro_pres.html#section-2",
    "title": "Time Series Forecasting",
    "section": "",
    "text": "flowchart LR\n    A(There are two types of Data Scientists)\n    A--&gt;B(Those who can't predict the future)\n    A--&gt;C(Those who don't know that they can't predict the future)\n\n\n\n\n\n\n\nNo one, except for sorcerers and wizards, can predict the future."
  },
  {
    "objectID": "docs/modules/module_1/01_intro/intro_pres.html#section-4",
    "href": "docs/modules/module_1/01_intro/intro_pres.html#section-4",
    "title": "Time Series Forecasting",
    "section": "",
    "text": "Dr. Strange didn’t have the Time stone. He was using a high-tech gamer PC to run millions of simulations."
  },
  {
    "objectID": "docs/modules/module_1/01_intro/intro_pres.html#eclipses",
    "href": "docs/modules/module_1/01_intro/intro_pres.html#eclipses",
    "title": "Time Series Forecasting",
    "section": "Eclipses",
    "text": "Eclipses\n\nWe can predict eclipses with complete certainty."
  },
  {
    "objectID": "docs/modules/module_1/01_intro/intro_pres.html#section-5",
    "href": "docs/modules/module_1/01_intro/intro_pres.html#section-5",
    "title": "Time Series Forecasting",
    "section": "",
    "text": "It’s not so easy to predict stock prices\n\n\n\n\n\nOther variables can’t be predicted that easily. What does it depend on?"
  },
  {
    "objectID": "docs/modules/module_1/01_intro/intro_pres.html#beer-production-forecasts",
    "href": "docs/modules/module_1/01_intro/intro_pres.html#beer-production-forecasts",
    "title": "Time Series Forecasting",
    "section": "Beer Production Forecasts",
    "text": "Beer Production Forecasts\n\n\n\n\n\n\n\nCan you observe any strange patterns?"
  },
  {
    "objectID": "docs/modules/module_1/01_intro/intro_pres.html#electricity-demand",
    "href": "docs/modules/module_1/01_intro/intro_pres.html#electricity-demand",
    "title": "Time Series Forecasting",
    "section": "Electricity Demand",
    "text": "Electricity Demand"
  },
  {
    "objectID": "docs/modules/module_1/01_intro/intro_pres.html#employment",
    "href": "docs/modules/module_1/01_intro/intro_pres.html#employment",
    "title": "Time Series Forecasting",
    "section": "Employment",
    "text": "Employment\n\n\n\n\n\nUS Retail Employment"
  },
  {
    "objectID": "docs/modules/module_1/02_time_series/r_time_series_pres.html#the-tidyverse",
    "href": "docs/modules/module_1/02_time_series/r_time_series_pres.html#the-tidyverse",
    "title": "RStudio, R, and Time Series",
    "section": "The tidyverse",
    "text": "The tidyverse\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\ntidyverse is a meta-package that loads the core packages of the tidyverse.\n\n\nWe will always load all the required packages a the beginning of the document. When loading the tidyverse, it shows which packages are being attached, as well as any conflicts with previously loaded packages.\n\n\n\n\n\n\nCore packages\n\n\n\ndplyr is the core package for data transformation. It is paired up with the following packages for specific column types:\n\nstringr for strings.\nforcats for factors (R’s categorical data type).\nlubridate for dates and date-times.\nggplot2 is the primary package for visualization."
  },
  {
    "objectID": "docs/modules/module_1/02_time_series/r_time_series_pres.html#the-tidyverts",
    "href": "docs/modules/module_1/02_time_series/r_time_series_pres.html#the-tidyverts",
    "title": "RStudio, R, and Time Series",
    "section": "The tidyverts",
    "text": "The tidyverts\n\nlibrary(fpp3)\n\nRegistered S3 method overwritten by 'tsibble':\n  method               from \n  as_tibble.grouped_df dplyr\n\n\n── Attaching packages ──────────────────────────────────────────── fpp3 1.0.1 ──\n\n\n✔ tsibble     1.1.6     ✔ feasts      0.4.1\n✔ tsibbledata 0.4.1     ✔ fable       0.4.1\n\n\n── Conflicts ───────────────────────────────────────────────── fpp3_conflicts ──\n✖ lubridate::date()    masks base::date()\n✖ dplyr::filter()      masks stats::filter()\n✖ tsibble::intersect() masks base::intersect()\n✖ tsibble::interval()  masks lubridate::interval()\n✖ dplyr::lag()         masks stats::lag()\n✖ tsibble::setdiff()   masks base::setdiff()\n✖ tsibble::union()     masks base::union()\n\n\n\nfpp3 is also a meta-package that load the tidyverts ecosystem for time series analysis and forecasting.\n\n\nThe tidyverts packages are made to work seamlessly with the tidyverse.\n\n\n\n\n\n\nNote\n\n\n\ntsibble is the main data structure we will use to analyze and model time series. It is a time series tibble.\nfeasts provides many functions and tools for feature and statistics extraction for time series.\nfable is the core package for modeling and foreasting time series."
  },
  {
    "objectID": "docs/modules/module_1/02_time_series/r_time_series_pres.html#tourism-in-australia",
    "href": "docs/modules/module_1/02_time_series/r_time_series_pres.html#tourism-in-australia",
    "title": "RStudio, R, and Time Series",
    "section": "Tourism in Australia",
    "text": "Tourism in Australia\n\ntourism\n\n\n  \n\n\n\n\nThe tsibble shows quarterly data on tourism across Australia. It’s divided by Region, State, and purspose of the trip. How many different states are there?"
  },
  {
    "objectID": "docs/modules/module_1/02_time_series/r_time_series_pres.html#australian-states",
    "href": "docs/modules/module_1/02_time_series/r_time_series_pres.html#australian-states",
    "title": "RStudio, R, and Time Series",
    "section": "Australian States",
    "text": "Australian States\n\ndistinct(tourism, State)"
  },
  {
    "objectID": "docs/modules/module_1/02_time_series/r_time_series_pres.html#which-regions-are-located-in-tasmania",
    "href": "docs/modules/module_1/02_time_series/r_time_series_pres.html#which-regions-are-located-in-tasmania",
    "title": "RStudio, R, and Time Series",
    "section": "Which regions are located in Tasmania?",
    "text": "Which regions are located in Tasmania?\n\ndistinct(filter(tourism, State == \"Tasmania\"),Region)"
  },
  {
    "objectID": "docs/modules/module_1/02_time_series/r_time_series_pres.html#data-transformation-average-trips",
    "href": "docs/modules/module_1/02_time_series/r_time_series_pres.html#data-transformation-average-trips",
    "title": "RStudio, R, and Time Series",
    "section": "Data Transformation: Average trips",
    "text": "Data Transformation: Average trips\nTo get the average trips by purpose, we need to do the following:\n\n\nFilter the original tsibble to get only the data from East Coast, Tasmania.\nConvert the data to a tibble.\nGroup by purpose.\nSummarise by getting the mean of the trips."
  },
  {
    "objectID": "docs/modules/module_1/02_time_series/r_time_series_pres.html#section",
    "href": "docs/modules/module_1/02_time_series/r_time_series_pres.html#section",
    "title": "RStudio, R, and Time Series",
    "section": "",
    "text": "With traditional code, this would look something like:\n\nsummarise(group_by(as_tibble(filter(tourism, State == \"Tasmania\", \n                                    Region == \"East Coast\")), Purpose),\n          mean_trips = mean(Trips))\n\n\n\n\n\n\n\n\nOrder of code execution\n\n\nNote that this code must be read inside-out. This makes it harder to understand, and also harder to debug."
  },
  {
    "objectID": "docs/modules/module_1/02_time_series/r_time_series_pres.html#section-1",
    "href": "docs/modules/module_1/02_time_series/r_time_series_pres.html#section-1",
    "title": "RStudio, R, and Time Series",
    "section": "",
    "text": "Using the native pipe operator; |&gt;, we can improve the same code:\n\ntourism |&gt;                          \n  filter()"
  },
  {
    "objectID": "docs/modules/module_1/02_time_series/r_time_series_pres.html#section-2",
    "href": "docs/modules/module_1/02_time_series/r_time_series_pres.html#section-2",
    "title": "RStudio, R, and Time Series",
    "section": "",
    "text": "Using the native pipe operator; |&gt;, we can improve the same code:\n\ntourism |&gt;                          \n  filter(State == \"Tasmania\",       \n         Region == \"East Coast\") |&gt;"
  },
  {
    "objectID": "docs/modules/module_1/02_time_series/r_time_series_pres.html#section-3",
    "href": "docs/modules/module_1/02_time_series/r_time_series_pres.html#section-3",
    "title": "RStudio, R, and Time Series",
    "section": "",
    "text": "Using the native pipe operator; |&gt;, we can improve the same code:\n\ntourism |&gt;                          \n  filter(State == \"Tasmania\",       \n         Region == \"East Coast\") |&gt; \n  as_tibble() |&gt;"
  },
  {
    "objectID": "docs/modules/module_1/02_time_series/r_time_series_pres.html#section-4",
    "href": "docs/modules/module_1/02_time_series/r_time_series_pres.html#section-4",
    "title": "RStudio, R, and Time Series",
    "section": "",
    "text": "Using the native pipe operator; |&gt;, we can improve the same code:\n\ntourism |&gt;                          \n  filter(State == \"Tasmania\",       \n         Region == \"East Coast\") |&gt; \n  as_tibble() |&gt;                    \n  group_by()"
  },
  {
    "objectID": "docs/modules/module_1/02_time_series/r_time_series_pres.html#section-5",
    "href": "docs/modules/module_1/02_time_series/r_time_series_pres.html#section-5",
    "title": "RStudio, R, and Time Series",
    "section": "",
    "text": "Using the native pipe operator; |&gt;, we can improve the same code:\n\ntourism |&gt;                          \n  filter(State == \"Tasmania\",       \n         Region == \"East Coast\") |&gt; \n  as_tibble() |&gt;                    \n  group_by(Purpose) |&gt;"
  },
  {
    "objectID": "docs/modules/module_1/02_time_series/r_time_series_pres.html#section-6",
    "href": "docs/modules/module_1/02_time_series/r_time_series_pres.html#section-6",
    "title": "RStudio, R, and Time Series",
    "section": "",
    "text": "Using the native pipe operator; |&gt;, we can improve the same code:\n\ntourism |&gt;                          \n  filter(State == \"Tasmania\",       \n         Region == \"East Coast\") |&gt; \n  as_tibble() |&gt;                    \n  group_by(Purpose) |&gt;              \n  summarise(mean_trips = )"
  },
  {
    "objectID": "docs/modules/module_1/02_time_series/r_time_series_pres.html#section-7",
    "href": "docs/modules/module_1/02_time_series/r_time_series_pres.html#section-7",
    "title": "RStudio, R, and Time Series",
    "section": "",
    "text": "Using the native pipe operator; |&gt;, we can improve the same code:\n\ntourism |&gt;                          \n  filter(State == \"Tasmania\",       \n         Region == \"East Coast\") |&gt; \n  as_tibble() |&gt;                    \n  group_by(Purpose) |&gt;              \n  summarise(mean_trips = mean(Trips))"
  },
  {
    "objectID": "docs/modules/module_1/02_time_series/r_time_series_pres.html#section-8",
    "href": "docs/modules/module_1/02_time_series/r_time_series_pres.html#section-8",
    "title": "RStudio, R, and Time Series",
    "section": "",
    "text": "Using the native pipe operator; |&gt;, we can improve the same code:\n\n1tourism |&gt;\n2  filter(State == \"Tasmania\",\n         Region == \"East Coast\") |&gt;\n3  as_tibble() |&gt;\n4  group_by(Purpose) |&gt;\n5  summarise(mean_trips = mean(Trips))\n\n\n1\n\nTake the tsibble tourism, then\n\n2\n\nfilter by State and Region, then\n\n3\n\nconvert to a tibble, then\n\n4\n\ngroup the tibble by purpose, then\n\n5\n\nsummarise by taking the mean trips\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nThe pipe operator |&gt;\n\n\nThe pipe is read as “then”, and it allows us to write code in the order it’s supposed to be run.\nIt also helps to debug code easier, because you can run each function in order and see where the error is."
  },
  {
    "objectID": "docs/modules/module_1/02_time_series/r_time_series_pres.html#ts-visualization",
    "href": "docs/modules/module_1/02_time_series/r_time_series_pres.html#ts-visualization",
    "title": "RStudio, R, and Time Series",
    "section": "TS Visualization",
    "text": "TS Visualization\n\ntourism |&gt; \n  filter(State == \"Tasmania\",\n         Region == \"East Coast\") |&gt; \n1  autoplot(Trips) +\n2  facet_wrap(vars(Purpose), scale = \"free_y\") +\n3  theme(legend.position = \"none\")\n\n\n1\n\nautoplot() detects the data automatically and proposes a plot accordingly.\n\n2\n\nfacet_wrap() Divides a plot into subplots (facets).\n\n3\n\nyou can customize endless feautres using theme(). Here, we remove the legend, as it’s redudant."
  },
  {
    "objectID": "docs/modules/module_1/02_time_series/r_time_series_pres.html#exporting-data-to-.csv",
    "href": "docs/modules/module_1/02_time_series/r_time_series_pres.html#exporting-data-to-.csv",
    "title": "RStudio, R, and Time Series",
    "section": "Exporting data to .csv",
    "text": "Exporting data to .csv\n\ntourism |&gt; \n  filter(State == \"Tasmania\",\n         Region == \"East Coast\") |&gt; \n  mutate(Quarter = as.Date(Quarter)) |&gt; \n  write_csv(\"./datos/tasmania.csv\")\n\n\nYou can export to .csv by providing a tsibble or tibble (or any other type of data frame), by calling write_csv(), and specifying the output file’s name."
  },
  {
    "objectID": "docs/modules/module_1/02_time_series/r_time_series.html",
    "href": "docs/modules/module_1/02_time_series/r_time_series.html",
    "title": "RStudio, R, and Time Series",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\ntidyverse is a meta-package that loads the core packages of the tidyverse.\n\n\nWe will always load all the required packages a the beginning of the document. When loading the tidyverse, it shows which packages are being attached, as well as any conflicts with previously loaded packages.\n\n\n\n\n\n\nCore packages\n\n\n\n\n\n\ndplyr is the core package for data transformation. It is paired up with the following packages for specific column types:\n\nstringr for strings.\nforcats for factors (R’s categorical data type).\nlubridate for dates and date-times.\nggplot2 is the primary package for visualization.\n\n\n\n\n\n\n\n\n\n\nlibrary(fpp3)\n\nRegistered S3 method overwritten by 'tsibble':\n  method               from \n  as_tibble.grouped_df dplyr\n\n\n── Attaching packages ──────────────────────────────────────────── fpp3 1.0.1 ──\n\n\n✔ tsibble     1.1.6     ✔ feasts      0.4.1\n✔ tsibbledata 0.4.1     ✔ fable       0.4.1\n\n\n── Conflicts ───────────────────────────────────────────────── fpp3_conflicts ──\n✖ lubridate::date()    masks base::date()\n✖ dplyr::filter()      masks stats::filter()\n✖ tsibble::intersect() masks base::intersect()\n✖ tsibble::interval()  masks lubridate::interval()\n✖ dplyr::lag()         masks stats::lag()\n✖ tsibble::setdiff()   masks base::setdiff()\n✖ tsibble::union()     masks base::union()\n\n\n\nfpp3 is also a meta-package that load the tidyverts ecosystem for time series analysis and forecasting.\n\n\nThe tidyverts packages are made to work seamlessly with the tidyverse.\n\n\n\n\n\n\nNote\n\n\n\n\n\n\ntsibble is the main data structure we will use to analyze and model time series. It is a time series tibble.\nfeasts provides many functions and tools for feature and statistics extraction for time series.\nfable is the core package for modeling and foreasting time series.",
    "crumbs": [
      "Modules",
      "Forecasting models based on decomposition methods",
      "RStudio, R, and Time Series"
    ]
  },
  {
    "objectID": "docs/modules/module_1/02_time_series/r_time_series.html#the-tidyverse",
    "href": "docs/modules/module_1/02_time_series/r_time_series.html#the-tidyverse",
    "title": "RStudio, R, and Time Series",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\ntidyverse is a meta-package that loads the core packages of the tidyverse.\n\n\nWe will always load all the required packages a the beginning of the document. When loading the tidyverse, it shows which packages are being attached, as well as any conflicts with previously loaded packages.\n\n\n\n\n\n\nCore packages\n\n\n\n\n\n\ndplyr is the core package for data transformation. It is paired up with the following packages for specific column types:\n\nstringr for strings.\nforcats for factors (R’s categorical data type).\nlubridate for dates and date-times.\nggplot2 is the primary package for visualization.",
    "crumbs": [
      "Modules",
      "Forecasting models based on decomposition methods",
      "RStudio, R, and Time Series"
    ]
  },
  {
    "objectID": "docs/modules/module_1/02_time_series/r_time_series.html#the-tidyverts",
    "href": "docs/modules/module_1/02_time_series/r_time_series.html#the-tidyverts",
    "title": "RStudio, R, and Time Series",
    "section": "",
    "text": "library(fpp3)\n\nRegistered S3 method overwritten by 'tsibble':\n  method               from \n  as_tibble.grouped_df dplyr\n\n\n── Attaching packages ──────────────────────────────────────────── fpp3 1.0.1 ──\n\n\n✔ tsibble     1.1.6     ✔ feasts      0.4.1\n✔ tsibbledata 0.4.1     ✔ fable       0.4.1\n\n\n── Conflicts ───────────────────────────────────────────────── fpp3_conflicts ──\n✖ lubridate::date()    masks base::date()\n✖ dplyr::filter()      masks stats::filter()\n✖ tsibble::intersect() masks base::intersect()\n✖ tsibble::interval()  masks lubridate::interval()\n✖ dplyr::lag()         masks stats::lag()\n✖ tsibble::setdiff()   masks base::setdiff()\n✖ tsibble::union()     masks base::union()\n\n\n\nfpp3 is also a meta-package that load the tidyverts ecosystem for time series analysis and forecasting.\n\n\nThe tidyverts packages are made to work seamlessly with the tidyverse.\n\n\n\n\n\n\nNote\n\n\n\n\n\n\ntsibble is the main data structure we will use to analyze and model time series. It is a time series tibble.\nfeasts provides many functions and tools for feature and statistics extraction for time series.\nfable is the core package for modeling and foreasting time series.",
    "crumbs": [
      "Modules",
      "Forecasting models based on decomposition methods",
      "RStudio, R, and Time Series"
    ]
  },
  {
    "objectID": "docs/modules/module_1/02_time_series/r_time_series.html#tourism-in-australia",
    "href": "docs/modules/module_1/02_time_series/r_time_series.html#tourism-in-australia",
    "title": "RStudio, R, and Time Series",
    "section": "Tourism in Australia",
    "text": "Tourism in Australia\n\ntourism\n\n\n  \n\n\n\n\nThe tsibble shows quarterly data on tourism across Australia. It’s divided by Region, State, and purspose of the trip. How many different states are there?",
    "crumbs": [
      "Modules",
      "Forecasting models based on decomposition methods",
      "RStudio, R, and Time Series"
    ]
  },
  {
    "objectID": "docs/modules/module_1/02_time_series/r_time_series.html#australian-states",
    "href": "docs/modules/module_1/02_time_series/r_time_series.html#australian-states",
    "title": "RStudio, R, and Time Series",
    "section": "Australian States",
    "text": "Australian States\n\ndistinct(tourism, State)",
    "crumbs": [
      "Modules",
      "Forecasting models based on decomposition methods",
      "RStudio, R, and Time Series"
    ]
  },
  {
    "objectID": "docs/modules/module_1/02_time_series/r_time_series.html#which-regions-are-located-in-tasmania",
    "href": "docs/modules/module_1/02_time_series/r_time_series.html#which-regions-are-located-in-tasmania",
    "title": "RStudio, R, and Time Series",
    "section": "Which regions are located in Tasmania?",
    "text": "Which regions are located in Tasmania?\n\ndistinct(filter(tourism, State == \"Tasmania\"),Region)",
    "crumbs": [
      "Modules",
      "Forecasting models based on decomposition methods",
      "RStudio, R, and Time Series"
    ]
  },
  {
    "objectID": "docs/modules/module_1/02_time_series/r_time_series.html#data-transformation-average-trips",
    "href": "docs/modules/module_1/02_time_series/r_time_series.html#data-transformation-average-trips",
    "title": "RStudio, R, and Time Series",
    "section": "Data Transformation: Average trips",
    "text": "Data Transformation: Average trips\nTo get the average trips by purpose, we need to do the following:\n\n\nFilter the original tsibble to get only the data from East Coast, Tasmania.\nConvert the data to a tibble.\nGroup by purpose.\nSummarise by getting the mean of the trips.",
    "crumbs": [
      "Modules",
      "Forecasting models based on decomposition methods",
      "RStudio, R, and Time Series"
    ]
  },
  {
    "objectID": "docs/modules/module_1/02_time_series/r_time_series.html#section",
    "href": "docs/modules/module_1/02_time_series/r_time_series.html#section",
    "title": "RStudio, R, and Time Series",
    "section": "",
    "text": "With traditional code, this would look something like:\n\nsummarise(group_by(as_tibble(filter(tourism, State == \"Tasmania\", \n                                    Region == \"East Coast\")), Purpose),\n          mean_trips = mean(Trips))\n\n\n\n\n\n\n\n\nOrder of code execution\n\n\n\n\n\nNote that this code must be read inside-out. This makes it harder to understand, and also harder to debug.",
    "crumbs": [
      "Modules",
      "Forecasting models based on decomposition methods",
      "RStudio, R, and Time Series"
    ]
  },
  {
    "objectID": "docs/modules/module_1/02_time_series/r_time_series.html#section-8",
    "href": "docs/modules/module_1/02_time_series/r_time_series.html#section-8",
    "title": "RStudio, R, and Time Series",
    "section": "",
    "text": "Using the native pipe operator; |&gt;, we can improve the same code:\n\n1tourism |&gt;\n2  filter(State == \"Tasmania\",\n         Region == \"East Coast\") |&gt;\n3  as_tibble() |&gt;\n4  group_by(Purpose) |&gt;\n5  summarise(mean_trips = mean(Trips))\n\n\n1\n\nTake the tsibble tourism, then\n\n2\n\nfilter by State and Region, then\n\n3\n\nconvert to a tibble, then\n\n4\n\ngroup the tibble by purpose, then\n\n5\n\nsummarise by taking the mean trips\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nThe pipe operator |&gt;\n\n\n\n\n\nThe pipe is read as “then”, and it allows us to write code in the order it’s supposed to be run.\nIt also helps to debug code easier, because you can run each function in order and see where the error is.",
    "crumbs": [
      "Modules",
      "Forecasting models based on decomposition methods",
      "RStudio, R, and Time Series"
    ]
  },
  {
    "objectID": "docs/modules/module_1/02_time_series/r_time_series.html#ts-visualization",
    "href": "docs/modules/module_1/02_time_series/r_time_series.html#ts-visualization",
    "title": "RStudio, R, and Time Series",
    "section": "TS Visualization",
    "text": "TS Visualization\n\ntourism |&gt; \n  filter(State == \"Tasmania\",\n         Region == \"East Coast\") |&gt; \n1  autoplot(Trips) +\n2  facet_wrap(vars(Purpose), scale = \"free_y\") +\n3  theme(legend.position = \"none\")\n\n\n1\n\nautoplot() detects the data automatically and proposes a plot accordingly.\n\n2\n\nfacet_wrap() Divides a plot into subplots (facets).\n\n3\n\nyou can customize endless feautres using theme(). Here, we remove the legend, as it’s redudant.",
    "crumbs": [
      "Modules",
      "Forecasting models based on decomposition methods",
      "RStudio, R, and Time Series"
    ]
  },
  {
    "objectID": "docs/modules/module_1/02_time_series/r_time_series.html#exporting-data-to-.csv",
    "href": "docs/modules/module_1/02_time_series/r_time_series.html#exporting-data-to-.csv",
    "title": "RStudio, R, and Time Series",
    "section": "Exporting data to .csv",
    "text": "Exporting data to .csv\n\ntourism |&gt; \n  filter(State == \"Tasmania\",\n         Region == \"East Coast\") |&gt; \n  mutate(Quarter = as.Date(Quarter)) |&gt; \n  write_csv(\"./datos/tasmania.csv\")\n\n\nYou can export to .csv by providing a tsibble or tibble (or any other type of data frame), by calling write_csv(), and specifying the output file’s name.",
    "crumbs": [
      "Modules",
      "Forecasting models based on decomposition methods",
      "RStudio, R, and Time Series"
    ]
  },
  {
    "objectID": "docs/modules/forecasting_wf_pres.html#packages",
    "href": "docs/modules/forecasting_wf_pres.html#packages",
    "title": "The Forecasting Workflow using fable",
    "section": "Packages",
    "text": "Packages\nIt is recommended to load all the packages at the beginning of your file. We will be using the tidyverts ecosystem for the whole forecasting workflow.\n\nlibrary(tidyverse)\nlibrary(fpp3)\nlibrary(plotly)\n\n\n\n\n\n\n\nWarning\n\n\nDo not load unnecesary packages into your environment. It could lead to conflicts between functions and unwanted results."
  },
  {
    "objectID": "docs/modules/forecasting_wf_pres.html#data",
    "href": "docs/modules/forecasting_wf_pres.html#data",
    "title": "The Forecasting Workflow using fable",
    "section": "Data",
    "text": "Data\nWe will work with the Real Gross Domestic Product (GDP) for Mexico. The data is downloaded from FRED. The time series id is NGDPRNSAXDCMXQ.\nImport data\n\ngdp &lt;- tidyquant::tq_get(\n  x    = \"NGDPRNSAXDCMXQ\",\n  get  = \"economic.data\",\n  from = \"1997-01-01\"\n)\n\ngdp\n\n\n  \n\n\n\nWrangle data\nThere are some issues with our data:\n\nIt is loaded into a tibble object. We need to convert it to a tsibble.\n\n\n\n\n\n\n\nTip\n\n\nWe can use as_tsibble() to do so.\n\n\n\n\nOur data is quarterly, but it is loaded in a YYYY-MM-DD format. We need to change it to a YYYY QQ format.\n\n\n\n\n\n\n\nTip\n\n\nThere are some functions that help us achieve this, such as\n\nyearquarter()\nyearmonth()\nyearweek()\nyear()\n\ndepending on the time series’ period.\n\n\n\nWe will overwrite our data:\n\ngdp &lt;- gdp |&gt; \n  mutate(date = yearquarter(date)) |&gt; \n  as_tsibble(\n    index = date,\n    key   = symbol\n  )\n\ngdp\n\n\n  \n\n\n\n\n\n\n\n\n\nTip\n\n\n\nWe always need to specify the index argument, as it is our date variable.\nThe key argument is necessary whenever we have more than one time series in our data frame and is made up of one or more columns that uniquely identify each time series ."
  },
  {
    "objectID": "docs/modules/forecasting_wf_pres.html#traintest-split",
    "href": "docs/modules/forecasting_wf_pres.html#traintest-split",
    "title": "The Forecasting Workflow using fable",
    "section": "Train/Test Split",
    "text": "Train/Test Split\nWe will split our data in two sets: a training set, and a test set, in order to evaluate our forecasts’ accuracy.\n\ngdp_train &lt;- gdp |&gt; \n  filter_index(. ~ \"2021 Q4\")\n\ngdp_train\n\n\n  \n\n\n\n\n\n\n\n\n\nNote\n\n\nFor all our variables, it is strongly recommended to follow the same notation process, and write our code using snake_case. Here, we called our data gdp, therefore, all the following variables will be called starting with gdp_1, such as gdp_train for our training set.\n\n\n\nThis will make it very convenient when calling your variables. RStudio will display all the options starting with gdp_. We will usually use the following suffixes:\n\n_train: training set\n_fit: the mable (table of models)\n_aug: the augmented table with fitted values and residuals\n_dcmp: for the dable (decomposition table), containing the components and the seasonally adjusted series of a TS decomposition.\n_fc or _fcst: for the fable (forecasts table) that has our forecasts."
  },
  {
    "objectID": "docs/modules/forecasting_wf_pres.html#visualization-and-eda",
    "href": "docs/modules/forecasting_wf_pres.html#visualization-and-eda",
    "title": "The Forecasting Workflow using fable",
    "section": "Visualization and EDA",
    "text": "Visualization and EDA\nWhen performing time series analysis/forecasting, one of the first things to do is to create a time series plot.\n\np &lt;- gdp_train |&gt; \n  autoplot(price) +\n  labs(\n    title = \"Time series plot of the Real GDP for Mexico\",\n    y = \"GDP\"\n  )\n \nggplotly(p, dynamicTicks = TRUE) |&gt; \n  rangeslider()\n\n\n\n\n\n\n\n\nOur data exhibits an upward linear trend (with some economic cycles), and strong yearly seasonality.\n\n\n\nWe will explore it further with a season plot.\n\ngdp_train |&gt; \n  gg_season(price) |&gt; \n  ggplotly()\n\n\n\n\n\nTS Decomposition\n\ngdp_train |&gt; \n  model(stl = STL(price, robust = TRUE)) |&gt; \n  components() |&gt; \n  autoplot() |&gt; \n  ggplotly()\n\n\n\n\n\n\n\n\nThe STL decomposition shows that the variance of the seasonal component has been increasing. We could try using a log transformation to counter this.\n\n\n\n\ngdp_train |&gt; \n  autoplot(log(price)) +\n  ggtitle(\"Log of the Real GDP of Mexico\")\n\n\n\n\n\n\n\n\n\ngdp_train |&gt; \n  model(stl = STL(log(price) ~ season(window = \"periodic\"), robust = TRUE)) |&gt; \n  components() |&gt; \n  autoplot() |&gt; \n  ggplotly()"
  },
  {
    "objectID": "docs/modules/forecasting_wf_pres.html#model-specification",
    "href": "docs/modules/forecasting_wf_pres.html#model-specification",
    "title": "The Forecasting Workflow using fable",
    "section": "Model Specification",
    "text": "Model Specification\nWe will fit two models to our time series: Seasonal Naïve, and the Drift model. We will also use the log transformation.\n\ngdp_fit &lt;- gdp_train |&gt; \n  model(\n    snaive = SNAIVE(log(price)),\n    drift  = RW(log(price) ~ drift())\n  )\n\n\n\n\n\n\n\nBenchmark models\n\n\nWe have four different benchmark models that we’ll use to compare against the rest of the more complex models:\n\nMean (MEAN( &lt;.y&gt; ))\nNaïve (NAIVE( &lt;.y&gt; ))\nSeasonal Naïve (SNAIVE( &lt;.y&gt; ))\nDrift (RW( &lt;.y&gt; ~ drift()))\n\nwhere &lt;.y&gt; is just a placeholder for the variable to model.\nChoose wisely which of these to use in each case, according to the exploratory analysis performed."
  },
  {
    "objectID": "docs/modules/forecasting_wf_pres.html#residuals-diagnostics",
    "href": "docs/modules/forecasting_wf_pres.html#residuals-diagnostics",
    "title": "The Forecasting Workflow using fable",
    "section": "Residuals Diagnostics",
    "text": "Residuals Diagnostics\nVisual analysis\n\ngdp_fit |&gt; \n  select(snaive) |&gt; \n  gg_tsresiduals() +\n  ggtitle(\"Residuals Diagnostics for the Seasonal Naïve Model\")\n\n\n\n\n\n\n\ngdp_fit |&gt; \n  select(drift) |&gt; \n  gg_tsresiduals() +\n  ggtitle(\"Residuals Diagnostics for the Drift Model\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\nHere we expect to see:\n\nA time series with no apparent patterns (no trend and/or seasonality), with a mean close to zero.\nIn the ACF, we’d expect no lags with significant autocorrelation.\nNormally distributed residuals.\n\n\n\n\nPortmanteau tests of autocorrelation\n\ngdp_fit |&gt; \n  augment() |&gt; \n  features(.innov, ljung_box, lag = 24, dof = 0)\n\n\n  \n\n\n\n\n\n\n\n\n\nResiduals interpretation\n\n\nBoth models produce sub optimal residuals:\n\nThe SNAIVE correctly detects the seasonality, however, its residuals are still autocorrelated. Moreover, the residuals are not normally distributed.\nThe drift model doesn’t account for the seasonality, and their distribution is a little bit skewed.\n\nHence, we will perform our forecasts using the bootstrapping method.\n\n\n\nWe can compute some error metrics on the training set using the accuracy() function:\n\ngdp_train_accu &lt;- accuracy(gdp_fit) |&gt; \n  arrange(MAPE)\ngdp_train_accu |&gt; \n  select(symbol:.type, MAPE, RMSE, MAE, MASE)\n\n\n  \n\n\n\n\n\n\n\n\n\nThe accuracy() function\n\n\nThe accuracy() function can be used to compute error metrics in the training data, or in the test set. What differs is the data that is given to it:\n\nFor the training metrics, you need to use the mable (the table of models, that we usually store in _fit).\nFor the forecasting error metrics, we need the fable (the forecasts table, usually stored as _fc or _fcst), and the complete set of data (both the training and test set together).\n\n\n\n\n\n\n\n\n\n\n\n\nFor this analysis, we are focusing on the MAPE1 metric. The drift model (2.47%) seems to have a better fit with the training set than the snaive model (3.24%).\n\n\n\nThe Mean Absolute Percentage Error is a percentage error metric widely used in professional environments.\nLet\n\\[\ne_t = y_t - \\hat{y}_t\n\\]\nbe the error or residual.\nThen the MAPE would be computed as\n\\[\nMAPE = \\frac{1}{T}\\sum_{t=1}^T|\\frac{e_t}{y_t}|\n\\]."
  },
  {
    "objectID": "docs/modules/forecasting_wf_pres.html#modeling-using-decomposition",
    "href": "docs/modules/forecasting_wf_pres.html#modeling-using-decomposition",
    "title": "The Forecasting Workflow using fable",
    "section": "Modeling using decomposition",
    "text": "Modeling using decomposition\nWe will perform a forecast using decomposition, to see if we can improve our results so far.\n\ngdp_fit_dcmp &lt;- gdp_train |&gt; \n      model(\n        stlf = decomposition_model(\n          STL(log(price) ~ season(window = \"periodic\"), robust = TRUE),\n          RW(season_adjust ~ drift())\n        )\n      )\n\ngdp_fit_dcmp\n\n\n  \n\n\n\n\n\n\n\n\n\nNote on decomposition_model()\n\n\nRemember, when using decomposition models, we need to do the following:\n\nSpecify what type of decomposition we want to use and customize it as needed.\nFit a model for the seasonally adjusted data; season_adjust.\nFit a model for the seasonal component. R uses a SNAIVE() model by default to model the seasonality. If you wish to model it using a different model, you have specify it.\n\n\nThe name of the seasonal component depends on the type of seasonality present in the time series. If it has a yearly seasonality, the component is called season_year. It could also be called season_week, season_day, and so on.\n\n\n\n\nWe can join this new model with the models we trained before. This way we can have them all in the same mable.\n\ngdp_fit &lt;- gdp_fit |&gt; \n  left_join(gdp_fit_dcmp)\n\nJoining with `by = join_by(symbol)`\n\n\nResiduals diagnostics\n\ngdp_fit |&gt; \n  accuracy() |&gt; \n  select(symbol:.type, MAPE, RMSE, MAE, MASE) |&gt; \n  arrange(MAPE)\n\n\n  \n\n\n\n\ngdp_fit |&gt; \n  select(stlf) |&gt; \n  gg_tsresiduals()\n\n\n\n\n\n\n\n\n\ngdp_fit |&gt; \n  augment() |&gt; \n  features(.innov, ljung_box)\n\n\n  \n\n\n\n\n\n\nThe MAPE seems to improve with this decomposition model. Also, the residual diagnostics do not show any seasonality present in them. However, the residuals are still autocorrelated, as the Ljung-Box test suggests."
  },
  {
    "objectID": "docs/modules/forecasting_wf_pres.html#forecasting-on-the-test-set",
    "href": "docs/modules/forecasting_wf_pres.html#forecasting-on-the-test-set",
    "title": "The Forecasting Workflow using fable",
    "section": "Forecasting on the test set",
    "text": "Forecasting on the test set\nOnce we have our models, we can produce forecasts. We will forecast our test data and check our forecasts’ performance.\n\ngdp_fc &lt;- gdp_fit |&gt; \n  forecast(h = gdp_h_fc) \n\ngdp_fc\n\n\n  \n\n\n\n\ngdp_fc |&gt; \n  autoplot(gdp) +\n  facet_wrap(~.model, ncol = 1)\n\n\n\n\n\n\n\ngdp_fc |&gt; \n  filter(.model == \"stlf\") |&gt; \n  autoplot(gdp)\n\n\n\n\n\n\n\n\nWe now estimate the forecast errors:\n\ngdp_fc |&gt; \n  accuracy(gdp) |&gt; \n  select(.model:.type, MAPE, RMSE, MAE, MASE) |&gt; \n  arrange(MAPE)"
  },
  {
    "objectID": "docs/modules/forecasting_wf_pres.html#forecasting-the-future",
    "href": "docs/modules/forecasting_wf_pres.html#forecasting-the-future",
    "title": "The Forecasting Workflow using fable",
    "section": "Forecasting the future",
    "text": "Forecasting the future\nWe now refit our model using the whole dataset. We will only model the STL decomposition model, because the other two didn’t get a strong fit.\n\ngdp_fit2 &lt;- gdp |&gt; \n  model(\n    stlf = decomposition_model(\n          STL(log(price) ~ season(window = \"periodic\"), robust = TRUE),\n          RW(season_adjust ~ drift())\n        )\n  )\ngdp_fit2\n\n\n  \n\n\n\n\ngdp_fc_fut &lt;- gdp_fit2 |&gt; \n  forecast(h = gdp_h_fc)\ngdp_fc_fut\n\n\n  \n\n\ngdp_fc_fut |&gt; \n  autoplot(gdp)\n\n\n\n\n\n\n\n\n\n# save(gdp_fc_fut, file = \"equipo1.RData\")"
  },
  {
    "objectID": "docs/modules/forecasting_workflow.html#packages",
    "href": "docs/modules/forecasting_workflow.html#packages",
    "title": "The Forecasting Workflow using fable",
    "section": "Packages",
    "text": "Packages\nIt is recommended to load all the packages at the beginning of your file. We will be using the tidyverts ecosystem for the whole forecasting workflow.\n\nlibrary(tidyverse)\nlibrary(fpp3)\nlibrary(plotly)\n\n\n\n\n\n\n\nWarning\n\n\n\nDo not load unnecesary packages into your environment. It could lead to conflicts between functions and unwanted results.",
    "crumbs": [
      "Modules",
      "Forecasting models based on decomposition methods",
      "The Forecasting Workflow"
    ]
  },
  {
    "objectID": "docs/modules/forecasting_workflow.html#data",
    "href": "docs/modules/forecasting_workflow.html#data",
    "title": "The Forecasting Workflow using fable",
    "section": "Data",
    "text": "Data\nWe will work with the Real Gross Domestic Product (GDP) for Mexico. The data is downloaded from FRED. The time series id is NGDPRNSAXDCMXQ.\n\nImport data\n\ngdp &lt;- tidyquant::tq_get(\n  x    = \"NGDPRNSAXDCMXQ\",\n  get  = \"economic.data\",\n  from = \"1997-01-01\"\n)\n\ngdp\n\n\n  \n\n\n\n\n\nWrangle data\nThere are some issues with our data:\n\nIt is loaded into a tibble object. We need to convert it to a tsibble.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nWe can use as_tsibble() to do so.\n\n\n\n\nOur data is quarterly, but it is loaded in a YYYY-MM-DD format. We need to change it to a YYYY QQ format.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nThere are some functions that help us achieve this, such as\n\nyearquarter()\nyearmonth()\nyearweek()\nyear()\n\ndepending on the time series’ period.\n\n\n\nWe will overwrite our data:\n\ngdp &lt;- gdp |&gt; \n  mutate(date = yearquarter(date)) |&gt; \n  as_tsibble(\n    index = date,\n    key   = symbol\n  )\n\ngdp\n\n\n  \n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nWe always need to specify the index argument, as it is our date variable.\nThe key argument is necessary whenever we have more than one time series in our data frame and is made up of one or more columns that uniquely identify each time series .",
    "crumbs": [
      "Modules",
      "Forecasting models based on decomposition methods",
      "The Forecasting Workflow"
    ]
  },
  {
    "objectID": "docs/modules/forecasting_workflow.html#traintest-split",
    "href": "docs/modules/forecasting_workflow.html#traintest-split",
    "title": "The Forecasting Workflow using fable",
    "section": "Train/Test Split",
    "text": "Train/Test Split\nWe will split our data in two sets: a training set, and a test set, in order to evaluate our forecasts’ accuracy.\n\ngdp_train &lt;- gdp |&gt; \n  filter_index(. ~ \"2021 Q4\")\n\ngdp_train\n\n\n  \n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFor all our variables, it is strongly recommended to follow the same notation process, and write our code using snake_case. Here, we called our data gdp, therefore, all the following variables will be called starting with gdp_1, such as gdp_train for our training set.",
    "crumbs": [
      "Modules",
      "Forecasting models based on decomposition methods",
      "The Forecasting Workflow"
    ]
  },
  {
    "objectID": "docs/modules/forecasting_workflow.html#visualization-and-eda",
    "href": "docs/modules/forecasting_workflow.html#visualization-and-eda",
    "title": "The Forecasting Workflow using fable",
    "section": "Visualization and EDA",
    "text": "Visualization and EDA\nWhen performing time series analysis/forecasting, one of the first things to do is to create a time series plot.\n\np &lt;- gdp_train |&gt; \n  autoplot(price) +\n  labs(\n    title = \"Time series plot of the Real GDP for Mexico\",\n    y = \"GDP\"\n  )\n \nggplotly(p, dynamicTicks = TRUE) |&gt; \n  rangeslider()\n\n\n\n\n\n\n\n\n\n\n\nOur data exhibits an upward linear trend (with some economic cycles), and strong yearly seasonality.\n\n\n\nWe will explore it further with a season plot.\n\ngdp_train |&gt; \n  gg_season(price) |&gt; \n  ggplotly()\n\n\n\n\n\n\nTS Decomposition\n\ngdp_train |&gt; \n  model(stl = STL(price, robust = TRUE)) |&gt; \n  components() |&gt; \n  autoplot() |&gt; \n  ggplotly()\n\n\n\n\n\n\n\n\n\n\n\nThe STL decomposition shows that the variance of the seasonal component has been increasing. We could try using a log transformation to counter this.\n\n\n\n\ngdp_train |&gt; \n  autoplot(log(price)) +\n  ggtitle(\"Log of the Real GDP of Mexico\")\n\n\n\n\n\n\n\n\n\ngdp_train |&gt; \n  model(stl = STL(log(price) ~ season(window = \"periodic\"), robust = TRUE)) |&gt; \n  components() |&gt; \n  autoplot() |&gt; \n  ggplotly()",
    "crumbs": [
      "Modules",
      "Forecasting models based on decomposition methods",
      "The Forecasting Workflow"
    ]
  },
  {
    "objectID": "docs/modules/forecasting_workflow.html#model-specification",
    "href": "docs/modules/forecasting_workflow.html#model-specification",
    "title": "The Forecasting Workflow using fable",
    "section": "Model Specification",
    "text": "Model Specification\nWe will fit two models to our time series: Seasonal Naïve, and the Drift model. We will also use the log transformation.\n\ngdp_fit &lt;- gdp_train |&gt; \n  model(\n    snaive = SNAIVE(log(price)),\n    drift  = RW(log(price) ~ drift())\n  )\n\n\n\n\n\n\n\nBenchmark models\n\n\n\n\n\nWe have four different benchmark models that we’ll use to compare against the rest of the more complex models:\n\nMean (MEAN( &lt;.y&gt; ))\nNaïve (NAIVE( &lt;.y&gt; ))\nSeasonal Naïve (SNAIVE( &lt;.y&gt; ))\nDrift (RW( &lt;.y&gt; ~ drift()))\n\nwhere &lt;.y&gt; is just a placeholder for the variable to model.\nChoose wisely which of these to use in each case, according to the exploratory analysis performed.",
    "crumbs": [
      "Modules",
      "Forecasting models based on decomposition methods",
      "The Forecasting Workflow"
    ]
  },
  {
    "objectID": "docs/modules/forecasting_workflow.html#residuals-diagnostics",
    "href": "docs/modules/forecasting_workflow.html#residuals-diagnostics",
    "title": "The Forecasting Workflow using fable",
    "section": "Residuals Diagnostics",
    "text": "Residuals Diagnostics\n\nVisual analysis\n\ngdp_fit |&gt; \n  select(snaive) |&gt; \n  gg_tsresiduals() +\n  ggtitle(\"Residuals Diagnostics for the Seasonal Naïve Model\")\n\n\n\n\n\n\n\ngdp_fit |&gt; \n  select(drift) |&gt; \n  gg_tsresiduals() +\n  ggtitle(\"Residuals Diagnostics for the Drift Model\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nHere we expect to see:\n\nA time series with no apparent patterns (no trend and/or seasonality), with a mean close to zero.\nIn the ACF, we’d expect no lags with significant autocorrelation.\nNormally distributed residuals.\n\n\n\n\n\n\nPortmanteau tests of autocorrelation\n\ngdp_fit |&gt; \n  augment() |&gt; \n  features(.innov, ljung_box, lag = 24, dof = 0)\n\n\n  \n\n\n\n\n\n\n\n\n\nResiduals interpretation\n\n\n\nBoth models produce sub optimal residuals:\n\nThe SNAIVE correctly detects the seasonality, however, its residuals are still autocorrelated. Moreover, the residuals are not normally distributed.\nThe drift model doesn’t account for the seasonality, and their distribution is a little bit skewed.\n\nHence, we will perform our forecasts using the bootstrapping method.\n\n\nWe can compute some error metrics on the training set using the accuracy() function:\n\ngdp_train_accu &lt;- accuracy(gdp_fit) |&gt; \n  arrange(MAPE)\ngdp_train_accu |&gt; \n  select(symbol:.type, MAPE, RMSE, MAE, MASE)\n\n\n  \n\n\n\n\n\n\n\n\n\nThe accuracy() function\n\n\n\n\n\nThe accuracy() function can be used to compute error metrics in the training data, or in the test set. What differs is the data that is given to it:\n\nFor the training metrics, you need to use the mable (the table of models, that we usually store in _fit).\nFor the forecasting error metrics, we need the fable (the forecasts table, usually stored as _fc or _fcst), and the complete set of data (both the training and test set together).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor this analysis, we are focusing on the MAPE2 metric. The drift model (2.47%) seems to have a better fit with the training set than the snaive model (3.24%).",
    "crumbs": [
      "Modules",
      "Forecasting models based on decomposition methods",
      "The Forecasting Workflow"
    ]
  },
  {
    "objectID": "docs/modules/forecasting_workflow.html#modeling-using-decomposition",
    "href": "docs/modules/forecasting_workflow.html#modeling-using-decomposition",
    "title": "The Forecasting Workflow using fable",
    "section": "Modeling using decomposition",
    "text": "Modeling using decomposition\nWe will perform a forecast using decomposition, to see if we can improve our results so far.\n\ngdp_fit_dcmp &lt;- gdp_train |&gt; \n      model(\n        stlf = decomposition_model(\n          STL(log(price) ~ season(window = \"periodic\"), robust = TRUE),\n          RW(season_adjust ~ drift())\n        )\n      )\n\ngdp_fit_dcmp\n\n\n  \n\n\n\n\n\n\n\n\n\nNote on decomposition_model()\n\n\n\n\n\nRemember, when using decomposition models, we need to do the following:\n\nSpecify what type of decomposition we want to use and customize it as needed.\nFit a model for the seasonally adjusted data; season_adjust.\nFit a model for the seasonal component. R uses a SNAIVE() model by default to model the seasonality. If you wish to model it using a different model, you have specify it.\n\n\nThe name of the seasonal component depends on the type of seasonality present in the time series. If it has a yearly seasonality, the component is called season_year. It could also be called season_week, season_day, and so on.\n\n\n\n\nWe can join this new model with the models we trained before. This way we can have them all in the same mable.\n\ngdp_fit &lt;- gdp_fit |&gt; \n  left_join(gdp_fit_dcmp)\n\nJoining with `by = join_by(symbol)`\n\n\n\nResiduals diagnostics\n\ngdp_fit |&gt; \n  accuracy() |&gt; \n  select(symbol:.type, MAPE, RMSE, MAE, MASE) |&gt; \n  arrange(MAPE)\n\n\n  \n\n\n\n\ngdp_fit |&gt; \n  select(stlf) |&gt; \n  gg_tsresiduals()\n\n\n\n\n\n\n\n\n\ngdp_fit |&gt; \n  augment() |&gt; \n  features(.innov, ljung_box)\n\n\n  \n\n\n\n\n\n\n\n\n\nThe MAPE seems to improve with this decomposition model. Also, the residual diagnostics do not show any seasonality present in them. However, the residuals are still autocorrelated, as the Ljung-Box test suggests.",
    "crumbs": [
      "Modules",
      "Forecasting models based on decomposition methods",
      "The Forecasting Workflow"
    ]
  },
  {
    "objectID": "docs/modules/forecasting_workflow.html#forecasting-on-the-test-set",
    "href": "docs/modules/forecasting_workflow.html#forecasting-on-the-test-set",
    "title": "The Forecasting Workflow using fable",
    "section": "Forecasting on the test set",
    "text": "Forecasting on the test set\nOnce we have our models, we can produce forecasts. We will forecast our test data and check our forecasts’ performance.\n\ngdp_fc &lt;- gdp_fit |&gt; \n  forecast(h = gdp_h_fc) \n\ngdp_fc\n\n\n  \n\n\n\n\ngdp_fc |&gt; \n  autoplot(gdp) +\n  facet_wrap(~.model, ncol = 1)\n\n\n\n\n\n\n\ngdp_fc |&gt; \n  filter(.model == \"stlf\") |&gt; \n  autoplot(gdp)\n\n\n\n\n\n\n\n\nWe now estimate the forecast errors:\n\ngdp_fc |&gt; \n  accuracy(gdp) |&gt; \n  select(.model:.type, MAPE, RMSE, MAE, MASE) |&gt; \n  arrange(MAPE)",
    "crumbs": [
      "Modules",
      "Forecasting models based on decomposition methods",
      "The Forecasting Workflow"
    ]
  },
  {
    "objectID": "docs/modules/forecasting_workflow.html#forecasting-the-future",
    "href": "docs/modules/forecasting_workflow.html#forecasting-the-future",
    "title": "The Forecasting Workflow using fable",
    "section": "Forecasting the future",
    "text": "Forecasting the future\nWe now refit our model using the whole dataset. We will only model the STL decomposition model, because the other two didn’t get a strong fit.\n\ngdp_fit2 &lt;- gdp |&gt; \n  model(\n    stlf = decomposition_model(\n          STL(log(price) ~ season(window = \"periodic\"), robust = TRUE),\n          RW(season_adjust ~ drift())\n        )\n  )\ngdp_fit2\n\n\n  \n\n\n\n\ngdp_fc_fut &lt;- gdp_fit2 |&gt; \n  forecast(h = gdp_h_fc)\ngdp_fc_fut\n\n\n  \n\n\ngdp_fc_fut |&gt; \n  autoplot(gdp)\n\n\n\n\n\n\n\n\n\n# save(gdp_fc_fut, file = \"equipo1.RData\")",
    "crumbs": [
      "Modules",
      "Forecasting models based on decomposition methods",
      "The Forecasting Workflow"
    ]
  },
  {
    "objectID": "docs/modules/forecasting_workflow.html#footnotes",
    "href": "docs/modules/forecasting_workflow.html#footnotes",
    "title": "The Forecasting Workflow using fable",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis will make it very convenient when calling your variables. RStudio will display all the options starting with gdp_. We will usually use the following suffixes:\n\n_train: training set\n_fit: the mable (table of models)\n_aug: the augmented table with fitted values and residuals\n_dcmp: for the dable (decomposition table), containing the components and the seasonally adjusted series of a TS decomposition.\n_fc or _fcst: for the fable (forecasts table) that has our forecasts. \n\n↩︎\nThe Mean Absolute Percentage Error is a percentage error metric widely used in professional environments.\nLet\n\\[\ne_t = y_t - \\hat{y}_t\n\\]\nbe the error or residual.\nThen the MAPE would be computed as\n\\[\nMAPE = \\frac{1}{T}\\sum_{t=1}^T|\\frac{e_t}{y_t}|\n\\].\n\n\n\n\n\n↩︎",
    "crumbs": [
      "Modules",
      "Forecasting models based on decomposition methods",
      "The Forecasting Workflow"
    ]
  }
]