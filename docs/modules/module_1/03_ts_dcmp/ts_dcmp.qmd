---
title: "Time Series Decomposition"
format:
  html:
    other-links: 
      - text: Guerrero feature
        href: https://github.com/pbenavidesh/narsil/blob/main/docs/bib/guerrero1993.pdf
  revealjs:
    output-file: ts_dcmp_pres.html
---

:::{.content-visible unless-format="revealjs"}

```{r}
#| label: pkgs
#| message: false

library(tidyverse)
library(fpp3)
library(tidyquant)
library(plotly)
```

:::

# TS Features & Patterns

:::{.content-hidden unless-format="revealjs"}

## 

:::

```{r}
#| label: ts-examples
#| echo: false
#| message: false
#| layout-ncol: 2

p1 <- tq_get("FARTCOIN-USD", from = "2024-01-01") |> 
  as_tsibble(index = date) |>
  autoplot(close, color = "navyblue") +
  labs(
    title = "Fartcoin",
    y = "USD",
    caption = "Source: Yahoo Finance"
  )

ggplotly(p1) |> 
  bslib::card(full_screen = TRUE)

p2 <- tq_get(
  "MEXLOCOEMORSTM",
  get = "economic.data",
  from = "1985-01-01"
) |>
  mutate(date = yearmonth(date)) |> 
  as_tsibble(index = date) |> 
  autoplot(price, color = "orchid") +
  labs(
    title = "Employment and Unemployment: Original Series for Mexico",
    y = "Percent",
    caption = "Source: Organization for Economic Co-operation and Development via FRED"
  ) +
  scale_y_continuous(labels = scales::percent_format(scale = 1)) 
 
ggplotly(p2, dynamicTicks = TRUE) |> 
  bslib::card(full_screen = TRUE)

p3 <- us_employment |>
  filter_index("1960 Jan." ~ .) |> 
  filter(Title == "Mining and Logging") |> 
  autoplot(color = "indianred1") +
  labs(
    title = "Mining and Logging Employment in the US",
    y = "Thousands of persons employed",
    caption = "Source = U.S. Bureau of Labor Statistics"
  )

ggplotly(p3, dynamicTicks = TRUE) |> 
  bslib::card(full_screen = TRUE)

mexretail <- tq_get(
  "MEXSLRTTO01IXOBM",
  get = "economic.data",
  from = "1985-01-01"
) |>
  mutate(date = yearmonth(date)) |> 
  rename(y = price) |>
  as_tsibble(index = date) 

p4 <- mexretail |> 
  autoplot(y, color = "springgreen4") +
  labs(
    title = "Retail Trade, Except of Motor Vehicles and Motorcycles for Mexico",
    y = "Index 2015=100",
    caption = "Organization for Economic Co-operation and Development via FRED"
  ) 
 
ggplotly(p4, dynamicTicks = TRUE)  |> 
  bslib::card(full_screen = TRUE)
```

:::{.notes}

All these time series have different shapes, patterns, and so on. When modeling them, we need to take these characteristics into account. We seek to understand the underlying patterns in the data to make better forecasts.

:::

## TS Patterns

Time series can have distinct patterns:

:::{.incremental}

- **Trend:** A long-term increase/decrease in the data.

- **Seasonal:** Fluctuations in the time series with a fixed and known period^[A time series can have multiple seasonal patterns.].

- **Cycles:** More commonly known as "Business cycles", refer to rises and falls that are not of a fixed frequency^[They usually last at least 2 years.].

- **Changes in variability:** Changes in the spread of the data over time, i. e., an increase/decrease in the variance as the level of the series increases/decreases.

:::


## Components of a Time Series

A time series can be decomposed into the following components:

:::{.incremental}

- **Seasonal component (S):** The repeating short-term cycle in the series.

- **Trend-cycle component (T):** The long-term progression of the series.

- **Residual component (R):** The residuals or "noise" left after removing the seasonal and trend-cycle components.

:::

# Mathematical Transformations

:::{.notes}

Transformations are used to stabilize the variance of a time series, making it easier to model and forecast. They can help to make the patterns in the data more apparent.

:::

## Log transformations

:::{.panel-tabset}

### Series in levels

```{r}
#| label: jj_levels
#| echo: false
#| message: false

jj <- JohnsonJohnson |> 
  as_tsibble()

p <- jj |> 
  autoplot() +
    ggtitle("J&J - Quarterly Sales")

ggplotly(p)

```

:::{.notes}

:::{.callout-note appearance="simple"}

Transformations and adjustments help us simplify the patterns in our data, and can improve our forecasts' accuracy.

:::

:::

### Log


```{r}
#| label: jj_log
#| echo: false
#| message: false

p <- jj |> 
  autoplot(log(value)) +
  ggtitle("J&J - Quarterly Sales")

ggplotly(p)
```

:::{.notes}

- Log transformations are often useful when the data presents an increasing/decreasing variation with the level of the series.

- Log transformations are very interpretable: changes in a log value are percent changes on the original scale.

:::


:::

## Box-Cox transformations


$$
w_t= \begin{cases}\log \left(y_t\right) & \text { if } \lambda=0 \\ \left(\operatorname{sign}\left(y_t\right)\left|y_t\right|^\lambda-1\right) / \lambda & \text { otherwise }\end{cases}
$$

:::{.notes}

In a Box-Cox transformation, the log is always a natural logarithm. The other case is just a power transformation with scaling.

:::


*What happens when $\lambda = 1$?*

:::{.callout-tip appearance="simple"}
You should choose a value of $\lambda$ that makes the size of the seasonal variation the same throughout the series.
:::

## How can we choose the value of $\lambda$?

We can use the `guerrero` feature to choose an optimal lambda.

```{r}
#| label: lambda_guerrero
#| code-line-numbers: "|2"
#| paged-print: false

aus_production |> 
  features(Gas, features = guerrero)
```


# Time Series Adjustments

## Calendar adjustments

::: {.panel-tabset}

### Closing price and volume

```{r}
#| label: calendar_google
#| echo: false

google <- tq_get("GOOG", from = "2018-01-01") |> 
  as_tsibble(index = date) 

p <- google |>
  select(date, close, volume) |> 
  pivot_longer(-date) |>
  autoplot(value) +
  facet_wrap(vars(name), scales = "free_y", ncol = 1) +
  theme(legend.position = "none") +
  ggtitle("Google: Daily Closing Price and Volume")

ggplotly(p, dynamicTicks = TRUE)
```

### Monthly aggregation

```{r}
#| label: google_monthly_data
google_month <- google |> 
  index_by(month = yearmonth(date)) |> 
  summarise(
    trading_days = n(),
    monthly_volume = sum(volume),
    mean_volume = mean(volume)
  )

google_month
```


### Monthly total and mean and volume

```{r}
#| label: google_monthly_vol
#| echo: false

p <- google_month |> 
  pivot_longer(-c(month:trading_days)) |>
  autoplot(value)  +
  facet_wrap(vars(name), scales = "free_y", ncol = 1) +
  theme(legend.position = "none")
  
ggplotly(p, dynamicTicks = TRUE) |> 
  rangeslider() |> 
  layout(yaxis = list(fixedrange = FALSE))
```

:::

::: {.notes}

- The number of trading days in a month can vary due to weekends and holidays, and not because of any economic reason.
- Using the monthly total volume can be misleading, as months with more trading days will naturally have higher total volumes.
- Using the mean volume per trading day helps to standardize the data, making it easier to compare across months.

:::
## Population adjustments

```{r}
#| label: global_economy
#| echo: false

ge <- global_economy |> 
  filter(Country %in% c("Mexico", "Iceland", "Australia"))

p <- ge |> 
  autoplot(GDP, size = 1) +
  labs(
    title = "GDP: Mexico, Iceland, and Australia"
    )

ggplotly(p, dynamicTicks = TRUE)
```

Is the Mexican economy really that similar Australia's economy? Is Iceland's economy really that small?

::: {.notes}

- A greater GDP can be interpreted as having a larger economy, and a better life standard, but this is not always the case.
- Comparing GDP across countries with different population sizes can be misleading.
- GDP is often used to measure the economic performance of a country, but it doesn't account for population size.
- The higher the population, the higher the GDP tends to be, simply because there are more people contributing to the economy.
- A more meaningful comparison can be made by looking at *GDP per capita*, which divides the GDP by the population size.

:::

##

::: {.panel-tabset}

### Population

```{r}
#| label: population
#| echo: false

p <- ge |> 
  autoplot(Population, size = 1) +
  labs(
    title = "Population: Mexico, Iceland, and Australia"
    )

ggplotly(p, dynamicTicks = TRUE)
```

The population sizes of these countries are very different.


### GDP per capita

```{r}
#| label: gdp_per_capita
#| echo: false

p <- ge |> 
  mutate(GDP_per_capita = GDP / Population) |> 
  autoplot(GDP_per_capita, size = 1) +
  labs(
    title = "GDP per capita: Mexico, Iceland, and Australia"
    )

ggplotly(p, dynamicTicks = TRUE)
```



::: {.notes}

- GDP per capita provides a more accurate representation of the economic well-being of individuals in a country.
- It is clear now that Iceland and Australia have a much higher GDP per capita compared to Mexico, indicating a higher standard of living for its residents.

:::
:::

## Inflation adjustments

::: {.incremental}

- Inflation is the rate at which the general level of prices for goods and services is rising, and subsequently, purchasing power is falling.
- To make meaningful comparisons of economic data over time, it is essential to adjust for inflation.
- This adjustment is typically done using a price index, such as the Consumer Price Index (CPI). In Mexico, the National Consumer Price Index (INPC) is used. INEGI provides this data.

:::

## Inflation adjustment formula

$$
x_t = \frac{y_t}{z_t} * z_{2010}
$$

::: {.notes}
where:

- $y_t$ is the original value at time $t$ (nominal value).
- $z_t$ is the price index at time $t$ (e.g., INPC).
- $z_{2010}$ is the price index in the base year (2010 in this case).
- $x_t$ is the inflation-adjusted value at time $t$ (real value).

:::

## Inflation adjustment example

:::{.panel-tabset}

### Nominal values

```{r}
#| label: inflation_adjustment
#| echo: false

print_retail <- aus_retail  |> 
  filter(Industry == "Newspaper and book retailing") |>
  group_by(Industry) |>
  index_by(Year = year(Month)) |>
  summarise(Turnover = sum(Turnover))

print_retail |> 
  autoplot(Turnover) +
  labs(
    title = "Turnover: Newspaper and book retailing"
  )
```
### Real values

```{r}
#| label: inflation_adjustment_real

aus_economy <- global_economy |>
  filter(Code == "AUS")


print_retail <- print_retail |> 
  left_join(aus_economy, by = "Year") |>
  mutate(Adjusted_turnover = Turnover / CPI) 
```

### Nominal vs. Real values

```{r}
#| label: inflation_adjustment_compare
#| echo: false
#| warning: false

p <- print_retail |> 
  pivot_longer(
    cols            = c(Turnover, Adjusted_turnover),
    names_to        = "Type",
    values_to       = "Turnover",
    names_transform = list(Type = as_factor) 
  ) |>
  autoplot(Turnover) +
  facet_wrap(vars(Type), scales = "free_y", ncol = 1) +
  theme(legend.position = "none") +
  ggtitle("Turnover: Newspaper and book retailing (Nominal vs. Real)")

ggplotly(p, dynamicTicks = TRUE)
```

:::

# Time Series Decomposition

## Types of Decompositions

:::{.notes}

A decomposition splits the time series into its underlying components:

- Trend-cycle
- Seasonal pattern(s)

And what's left of it we simply call it a "remainder component".

In general, there are two types of decompositions:

:::


### Additive decomposition

$$
y_t = T_t + S_t + R_t
$$

### Multiplicative decomposition

$$
y_t = T_t \times S_t \times R_t \\
$$



- *Which one should you use?*


:::{.notes}
- If the seasonal variation is roughly constant over time, use an additive decomposition.
- If the seasonal variation increases or decreases with the level of the series, use a multiplicative decomposition.
- If you're unsure, you can try both and see which one provides a better fit.


A multiplicative decomposition is equivalent to an additive decomposition of the log-transformed series:

$$
y_t = T_t \times S_t \times R_t
$$

is equivalent to

$$
\log(y_t) = \log(T_t) + \log(S_t) + \log(R_t)
$$

:::

## Seasonally adjusted series

:::{.notes}

One use of decomposition is to obtain a seasonally adjusted series, which is the original series with the seasonal component removed.

Seasonally adjusted series can be useful for:
- Identifying and analyzing the trend-cycle component without the influence of seasonal fluctuations.
- Making comparisons across different time periods without seasonal effects.

:::

- For an additive decomposition, the seasonally adjusted series is given by:
$$
y_t - S_t
$$
- For a multiplicative decomposition, the seasonally adjusted series is given by:
$$
\frac{y_t}{S_t}
$$


## Classical decomposition

In a classical decomposition, the trend-cycle component is estimated using a moving average. Then, the seasonal component is estimated by averaging the detrended values for each season. Finally, the remainder component is obtained by subtracting the trend-cycle and seasonal components from the original series.

An $m$ order moving average is given by:

$$
\hat{T}_{t}=\frac{1}{m} \sum_{j=-k}^{k} y_{t+j}
$$

where $k = (m-1)/2$^[In R, you can compute any moving average by using the `slider::slide_dbl()` function.].


:::{.content-hidden unless-format="revealjs"}

## Example of a classical decomposition {auto-animate="true"}

```{r}
#| label: classical_decomp_1

mexretail
```

## Example of a classical decomposition {auto-animate="true"}

```{r}
#| label: classical_decomp_2
#| eval: false

mexretail |> 
  model() # <1>
```

1. The function `model()` is used to specify one or more models for the `tsibble`.

## Example of a classical decomposition {auto-animate="true"}

```{r}
#| label: classical_decomp_3
#| eval: false

mexretail |> 
  model(
    classical = classical_decomposition() # <2>
  )
```

2. Inside the `model()` function, we specify the type of models we want to use. 

## Example of a classical decomposition {auto-animate="true"}

```{r}
#| label: classical_decomp_4
#| eval: true
#| df-print: default

mexretail |> 
  model(
    classical = classical_decomposition(y, type = "additive") # <2>
  )
```

2. In any model used, the first thing we need to specify is our forecast variable. Then, depending on the model used, we can specify additional parameters. The `model()` function yields a `mable`^[short for "model table"], which is a table that contains the fitted models for each time series in the `tsibble`.

## Example of a classical decomposition {auto-animate="true"}

```{r}
#| label: classical_decomp_5
#| eval: true

mexretail |> 
  model(
    classical = classical_decomposition(y, type = "additive") 
  ) |> 
  components() # <3>
```

3. The `components()` function is used to extract the components of the decomposition (trend-cycle, seasonal, and remainder) from the fitted models in the `mable`. It also provides the seasonally adjusted series.

:::

## Example of a classical decomposition {auto-animate="true"}

```{r}
#| label: classical_decomp_full

mexretail_dcmp <- mexretail |>                                # <1>
  model(                                                      # <2>
    classical = classical_decomposition(y, type = "additive") # <3>
  ) |> 
  components()                                                # <4>

mexretail_dcmp                                                # <5>
```

1. We start with our original `tsibble`.
2. Inside the `model()` function, we specify the type of models we want to use. 
3. In any model used, the first thing we need to specify is our forecast variable. Then, depending on the model used, we can specify additional parameters. The `model()` function yields a `mable`^[short for "model table"], which is a table that contains the fitted models for each time series in the `tsibble`.
4. The `components()` function is used to extract the components of the decomposition (trend-cycle, seasonal, and remainder) from the fitted models in the `mable`. It also provides the seasonally adjusted series.
5. Finally, we store the result.


## Example of a classical decomposition {auto-animate="true"}

```{r}
#| label: classical_decomp_plot
#| warning: false

mexretail_dcmp |> 
  autoplot()
```


## Problems of using a Classical decomposition

:::{.incremental}

- The trend-cycle component is not estimated at the beginning and end of the series. This can be problematic if you want to forecast the series.
- It also tends to over-smooth rises and falls.
- It assumes that the seasonal component is constant over time, which may not be the case in many real-world scenarios.
- It is not robust to outliers, which can significantly affect the estimates of the components.

:::

:::{.notes}

:::{.callout-warning}
It is not recommended to use classical decomposition for forecasting because of these issues.

:::

:::

## STL decomposition


:::{.notes}
STL (Seasonal and Trend decomposition using Loess) is a more advanced method for decomposing time series data^[There are other decomposition methods primarily used by official statistics agencies, such as X-11, X-12-ARIMA, and TRAMO/SEATS. However, these methods are not as widely used in the forecasting community as STL. For more on these, see [this](https://otexts.com/fpp3/methods-used-by-official-statistics-agencies.html).]. It uses locally weighted regression (loess) to estimate the trend-cycle and seasonal components. STL is more flexible than classical decomposition and can handle changes in the seasonal component over time.

:::
::: {.incremental}

- It can handle any type of seasonality (not just fixed periods).
- It can handle changes in the seasonal component over time.
- It is robust to outliers.
- It can be used for forecasting.
- It provides a way to control the smoothness of the trend and seasonal components through parameters.

:::{.callout-warning appearance="simple"}
- STL cannot automatically handle calendar or holiday variations.

- It only provides methods for additive models. If your data has multiplicative seasonality, you should log-transform the data before applying STL.

:::

:::

:::{.content-hidden unless-format="revealjs"}

## STL in R using `fable` {auto-animate="true"}


```{r}
#| label: stl_decomp_1

mexretail_stl <- mexretail |>                                
  model(                                                      
    stl = STL(y)
  ) |> 
  components()
```



## STL in R using `fable` {auto-animate="true"}


```{r}
#| label: stl_decomp_2

mexretail_stl <- mexretail |>                                
  model(                                                      
    stl = STL(y ~ trend(window = NULL))
  ) |> 
  components()
```


## STL in R using `fable` {auto-animate="true"}


```{r}
#| label: stl_decomp_3

mexretail_stl <- mexretail |>                                
  model(                                                      
    stl = STL(y ~ trend()) 
  ) |> 
  components()
```


:::

## STL in R using `fable`{auto-animate="true"}

::: {.notes}

The code is basically the same as for the classical decomposition. We just need to change the model used inside the `model()` function.

:::

```{r}
#| label: stl_decomp_full

mexretail |>                                
  model(                                                      
    stl = STL(y ~                            # <1>
                trend(window = NULL) +       # <2>
                season(window = "periodic"), # <3>
              robust = TRUE)                 # <4> 
  ) |> 
  components() |> 
  autoplot()
```

1. Inside the `STL()` function, we can specify the formula for the decomposition, or don't specify it at all. See [`?STL`](https://feasts.tidyverts.org/reference/STL.html) for more details.
2. The `trend()` function is used to specify the trend component of the decomposition. The `window` argument controls the smoothness of the trend component. A larger window results in a smoother trend.
3. The `season()` function is used to specify the seasonal component of the decomposition. The `window` argument controls the smoothness of the seasonal component. Setting it to "periodic" means that the seasonal component will be fixed over time.
4. The `robust` argument, when set to `TRUE`, makes the STL decomposition more robust to outliers in the data, so the effect of such values is sent to the residual component.


::: {.callout-tip collapse="true"}
## Writing formulas in R

In R, we use "$\sim$" instead of "$=$" in formula specification, i.e., $y \sim mx + b$.
:::

