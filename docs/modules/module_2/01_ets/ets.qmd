---
title: "Exponential smoothing"
format:
  html: default
  revealjs:
    output-file: ets_pres.html
---


```{r}
#| label: pkgs
#| message: false
#| include: false

library(tidyverse)
library(fpp3)
library(plotly)
```


:::{.content-hidden unless-format="revealjs"}

## {auto-animate=true}
::: {.r-hstack style="justify-content:space-between; align-items:center; margin-top:50px;"}
::: {data-id="mean"  style="background:#2F855A; color:white; padding:10px 14px; border-radius:12px;"}
**Mean**  
$$
\hat y_{T+1\mid T}=\tfrac{1}{T}\sum_{i=1}^T y_i
$$

:::

::: {data-id="axis" style="flex:1; height:10px; margin:0 16px; border-radius:6px; background: linear-gradient(90deg,#2F855A,#2CA1C2,#C0392B);"} 
:::

::: {data-id="naive" style="background:#C0392B; color:white; padding:10px 14px; border-radius:12px;"}
**Naïve**  
$$
\hat y_{T+1\mid T}=y_T
$$

:::
:::


## {auto-animate=true}
::: {.r-hstack style="justify-content:space-between; align-items:center; margin-top:50px;"}
::: {data-id="mean"  style="background:#2F855A; color:white; padding:10px 14px; border-radius:12px; opacity:.9;"}
**Mean** 
:::

::: {data-id="axis" style="flex:1; height:10px; margin:0 16px; border-radius:6px; background: linear-gradient(90deg,#2F855A,#2CA1C2,#C0392B);"} 
:::

::: {data-id="naive" style="background:#C0392B; color:white; padding:10px 14px; border-radius:12px; opacity:.9;"} 
**Naïve** 
:::

::: {data-id="ets" style="position:absolute; left:50%; transform:translateX(-50%); top:20%; background:#2CA1C2; color:white; padding:16px 20px; border-radius:14px; box-shadow:0 6px 18px #0006;"}
**Exponential Smoothing**  
$$
\hat y_{T+1\mid T}=\alpha y_T +  \alpha(1-\alpha)y_{T-1} + \ldots 
$$  

- $\alpha \approx 1$: naïve-like

- $\alpha \approx 0$: mean-like


:::
:::

:::

:::{.notes}

- Exponential smoothing methods are still relatively simple: they're simply weighted averages from historical data. 
  - However, these forecasting methods are widely used in practice, and they can be very effective.

- The exponential smoothing method is a compromise between the mean and naïve methods. It uses all historical data, but it assigns exponentially decreasing weights to older observations.

  - In the *mean* method, all observations are weighted equally (all have the same importance), while in the *naïve* method, only the most recent observation is used for forecasting. (we ignore all previous observations).

- The smoothing parameter $\alpha$ controls the rate of decrease: 
  - when $\alpha$ is close to 1, the method behaves like the naïve method, giving more weight to recent observations; 
  - when $\alpha$ is close to 0, it behaves like the mean method, giving more equal weight to all observations.

:::

:::{.content-hidden unless-format="revealjs"}
##
:::

$$
\hat{y}_{T+1 | T}= \alpha y_{T} + \alpha(1-\alpha) y_{T-1} + \alpha(1-\alpha)^{2} y_{T-2}  + \ldots
$$

where $0\leq \alpha \leq1$ is the smoothing parameter.

  

Table: Weights for different values of $\alpha$ {#tbl-ets_alpha_weights}

|              | $\alpha = 0.2$ | $\alpha = 0.4$ | $\alpha = 0.6$ | $\alpha = 0.8$ |
|--------------|:--------------:|:--------------:|:--------------:|:--------------:|
| $y_t$        | 0.2000         | 0.4000         | 0.6000         | 0.8000         |
| $y_{t-1}$    | 0.1600         | 0.2400         | 0.2400         | 0.1600         |
| $y_{t-2}$    | 0.1280         | 0.1440         | 0.0960         | 0.0320         |
| $y_{t-3}$    | 0.1024         | 0.0864         | 0.0384         | 0.0064         |
| $y_{t-4}$    | 0.0819         | 0.0518         | 0.0154         | 0.0013         |
| $y_{t-5}$    | 0.0655         | 0.0311         | 0.0061         | 0.0003         |



:::{.notes}
- $\alpha$ can be thought of as the *memory* of the time series: The smaller the value of $\alpha$, the longer the memory (i.e., the more past observations are taken into account). 

- Conversely, a larger value of $\alpha$ means a shorter memory, with more emphasis on recent observations. See @tbl-ets_alpha_weights for some examples.
:::

# Exponential smoothing methods

## Simple exponential smoothing (SES)

$$
\begin{aligned}
\text{Forecast equation} \quad & \hat{y}_{t+h|t} = \ell_t \\
\text{Smoothing equation} \quad & \ell_t = \alpha y_t + (1-\alpha)\ell_{t-1}
\end{aligned}
$$

where $\ell_t$ is the level at time $t$.

:::{.callout-note appearance="simple"}
SES has a flat forecast function, so it is appropriate for data with **no trend** or **seasonal** pattern.
:::

::: {.content-hidden unless-format="revealjs"}

##

:::

```{r}
#| label: alg-plot

algeria_economy <- global_economy |>
  filter(Country == "Algeria")
  
algeria_economy |> 
  autoplot(Exports)
```


```{r}
#| label: ses



alg_fit <- algeria_economy |>
  model(
    SES = ETS(Exports ~ error("A") + trend("N") + season("N")),
    Naive = NAIVE(Exports)
  )

alg_fc <- alg_fit |>
  forecast(h = 5)
```

::: {.content-visible unless-format="revealjs"}

:::{.callout-tip appearance="simple"}
## Benchmark methods for SES

The **mean** and **naïve** methods are typically the best fit as benchmark methods when using SES.

:::

:::

::: {.callout-note collapse="true"}
## Obtaining the `report()` of a model 
```{r}
#| label: ses-report

alg_fit |> 
  select(SES) |> 
  report()        #<1>
```

1. The `report()` function allows us to see a model's report (the time series modeled, the model used, the estimated parameters, and more). It needs a $1 \times 1$ dimension `mable`^[(i.e., a `mable` containing only one model and one time series.)]. 

:::

::: {.content-hidden unless-format="revealjs"}

##

:::

```{r}
#| label: ses-plot
#| echo: false

alg_fc |> 
  filter(.model == "SES") |> 
  autoplot(algeria_economy) +
  geom_line(aes(y = .fitted), color = "darkorange",
            data = alg_fit |> select(SES) |> augment()) +
  labs(
    x = "",
    y = "% of GDP", 
    title = "Forecasting Algeria's exports using SES"
  ) #+
  # guides(color = "none")
```

::: {.content-hidden unless-format="revealjs"}

##

:::

Comparing the SES and Naive forecasts:

```{r}
#| label: ses-v-naive-plot
#| echo: false

alg_fc |> 
  autoplot(algeria_economy |> filter_index(2005 ~ .), level = NULL) +
  labs(
    x = "",
    y = "% of GDP",
    title = "Forecasting using SES vs. Naive",
    caption = "Why is the SES forecast below the Naive here?"
  )
```


::: {.content-hidden unless-format="revealjs"}

# Methods with trend

:::

::: {.content-visible unless-format="revealjs"}

## Methods with trend

:::

::: {.content-hidden unless-format="revealjs"}

## Holt's linear trend

:::

::: {.content-visible unless-format="revealjs"}

### Holt's linear trend

:::

::: {.notes}
We can extend SES models to allow our forecasts to include trend in the data. We need to add a new smoothing parameter $\beta^*$, and its corresponding smoothing equation:
:::

$$
\begin{aligned}
\text{Forecast equation} \quad & \hat{y}_{t+h|t} = \ell_t + hb_t \\
\text{Level equation} \quad & \ell_t = \alpha y_t + (1-\alpha)\ell_{t-1}\\
\text{Trend equation} \quad & b_t = \beta^*(l_t-l_{t-1}) + (1-\beta^*)b_{t-1}
\end{aligned}
$$

where $b_t$ is the growth (or slope) at time $t$.

:::{.callout-tip collapse="true"}
## When to use Holt's linear trend method
- Holt's linear trend method is appropriate for data with a **linear trend** but **no seasonal** pattern.
- The proper benchmark method to compare against is the **drift** method. 
:::

::: {.notes}

Let's see an example using Holt's linear trend method to forecast Brazil's population.

:::

::: {.content-visible unless-format="revealjs"}

```{r}
#| label: bra-pop

bra_economy <- global_economy |> 
  filter(Code == "BRA") |> 
  mutate(Pop = Population / 1e6)

bra_economy |> 
  autoplot(Pop)
```

:::

::: {.content-hidden unless-format="revealjs"}

##

```{r}
#| label: bra-pop-plot
#| echo: false

bra_economy |> 
  autoplot(Pop)
```

:::


::: {.content-hidden unless-format="revealjs"}

## Forecasting Brazil's population {auto-animate="true"}

```{r}
#| label: holt_1

bra_fit <- bra_economy |> 
  model(
    Holt  = ETS(Pop ~ error("A") + trend("A") + season("N"))
  )

bra_fit
```

## Forecasting Brazil's population {auto-animate="true"}

```{r}
#| label: holt_2

bra_fit <- bra_economy |> 
  model(
    Holt  = ETS(Pop ~ error("A") + trend("A") + season("N")),
    Drift = RW(Pop ~ drift())
  )

bra_fit
```

## Forecasting Brazil's population {auto-animate="true"}

```{r}
#| label: holt_3

bra_fit <- bra_economy |> 
  model(
    Holt  = ETS(Pop ~ error("A") + trend("A") + season("N")),
    Drift = RW(Pop ~ drift())
  )

bra_fit |>  
  select(Holt) |>  
  report()
```


:::

::: {.content-hidden unless-format="revealjs"}

## Forecasting Brazil's population {auto-animate="true"}

:::

::: {.content-visible unless-format="revealjs"}

#### Forecasting Brazil's population

:::


```{r}
#| label: holt_full

bra_fit <- bra_economy |> 
  model(
    Holt  = ETS(Pop ~ error("A") + trend("A") + season("N")), #<1>
    Drift = RW(Pop ~ drift())
  )

bra_fit |>  
  select(Holt) |>  
  report()

bra_fc <- bra_fit |>  
  forecast(h = 15)

bra_fc |> 
  autoplot(bra_economy, level = NULL) +
  labs(title = "Brazilian population",
       y = "Millions") +
  guides(colour = guide_legend(title = "Forecast"))
```

1. We specify `trend("A")` to indicate that we want a linear trend. The model will estimate the smoothing parameters $\alpha$ and $\beta^*$ automatically.

::: {.content-hidden unless-format="revealjs"}

## Damped trend

:::

::: {.content-visible unless-format="revealjs"}

### Damped trend

:::

::: {.notes}
- Holt's linear trend method assume that the trend will continue indefinitely at the same rate. However, in many real-world scenarios, this assumption may not hold true. This methods tend to overestimate (*or underestimate*) long-term forecasts when the trend is strong.

- We can include a damping parameter $\phi$, which reduces the trend over time.
:::

$$
\begin{aligned}
\text{Forecast equation} \quad & \hat{y}_{t+h|t} = \ell_t +  (\phi + \phi^2 + \ldots + \phi^h) b_t \\
\text{Level equation} \quad & \ell_t = \alpha y_t + (\ell_{t-1} + \phi b_{t-1}) \\
\text{Trend equation} \quad & b_t = \beta^*(\ell_t-\ell_{t-1}) + (1-\beta^*)\phi b_{t-1}
\end{aligned}
$$

where $0 < \phi < 1$^[In practice, we restrict $0.8 \leq \phi \leq 0.98$ because the damping effect would be too great for smaller values than 0.8 and almost non distinguishable from a linear trend for greater values than 0.98.] is the damping parameter.

::: {.callout-caution collapse="true"}
## What would happen if $\phi = 1$? What about if $\phi = 0$?
- If $\phi = 1$, the model reduces to Holt's linear trend method, meaning the trend continues indefinitely at the same rate.
- If $\phi = 0$, the trend component is completely eliminated, and the model behaves like simple exponential smoothing (SES), where forecasts are based solely on the level component without any trend influence.
:::


::: {.content-hidden unless-format="revealjs"}

## Forecasting Brazil's population {auto-animate="true"}

```{r}
#| label: damped_1

bra_economy |> 
  model(
    Holt   = ETS(Pop ~ error("A") + trend("A") + season("N"))
  )
```

## Forecasting Brazil's population (continued) {auto-animate="true"}

```{r}
#| label: damped_2

bra_economy |> 
  model(
    Holt   = ETS(Pop ~ error("A") + trend("A") + season("N")),
    Damped = ETS(Pop ~ error("A") + trend("Ad", phi = 0.9) + season("N"))
  )
```

:::

::: {.content-hidden unless-format="revealjs"}

## Forecasting Brazil's population (continued) {auto-animate="true"}

:::

::: {.content-visible unless-format="revealjs"}

#### Forecasting Brazil's population (continued)

:::

```{r}
#| label: damped_full

bra_economy |> 
  model(
    Holt   = ETS(Pop ~ error("A") + trend("A") + season("N")),
    Damped = ETS(Pop ~ error("A") + trend("Ad", phi = 0.9) + season("N")) #<1>
  ) |> 
  forecast(h = 15) |> 
  autoplot(bra_economy, level = NULL) +
  labs(title = "Brazilian population",
       y = "Millions") +
  guides(colour = guide_legend(title = "Forecast"))
```

1. We specify `trend("Ad")` to indicate that we want a damped trend, and `phi = 0.9` sets the damping parameter to 0.9. We could also let the model estimate $\phi$ automatically by omitting the `phi` argument.

::: {.content-hidden unless-format="revealjs"}

# Methods with seasonality

:::

::: {.content-visible unless-format="revealjs"}

## Methods with seasonality

:::

::: {.content-hidden unless-format="revealjs"}

## Holt-Winters method

:::

::: {.content-visible unless-format="revealjs"}

### Holt-Winters method

:::

::: {.content-hidden unless-format="revealjs"}

### HW - Additive

:::

::: {.content-visible unless-format="revealjs"}

#### HW - Additive

:::


$$
\begin{aligned}
\text{Forecast equation} \quad & \hat{y}_{t+h|t} = \ell_t + hb_t + s_{t+h-m(k+1)} \\
\text{Level equation} \quad & \ell_t = \alpha (y_t - s_{t-m}) + (1 - \alpha) (\ell_{t-1} + b_{t-1}) \\
\text{Trend equation} \quad & b_t = \beta^*(\ell_t-\ell_{t-1}) + (1-\beta^*) b_{t-1} \\
\text{Seasonal equation} \quad & s_t = \gamma(y_t - \ell_{t-1} - b_{t-1}) + (1-\gamma)s_{t-m}
\end{aligned}
$$

where $s_t$ is the seasonal component at time $t$, $m$ is the period of the seasonality^[e.g., $m=4$ for quarterly data, $m=12$ for monthly data, ...], and $k = \lfloor (h-1)/m \rfloor$.

::: {.content-hidden unless-format="revealjs"}

### HW - Multiplicative

:::

::: {.content-visible unless-format="revealjs"}

#### HW - Multiplicative

:::

$$
\begin{aligned}
\text{Forecast equation} \quad & \hat{y}_{t+h|t} = (\ell_t + hb_t) s_{t+h-m(k+1)} \\
\text{Level equation} \quad & \ell_t = \alpha \frac{y_t}{s_{t-m}} + (1 - \alpha)(\ell_{t-1} + b_{t-1}) \\
\text{Trend equation} \quad & b_t = \beta^*(\ell_t-\ell_{t-1}) + (1-\beta^*) b_{t-1} \\
\text{Seasonal equation} \quad & s_t = \gamma \frac{y_t}{\ell_{t-1} + b_{t-1}} + (1-\gamma)s_{t-m}
\end{aligned}
$$

::: {.callout-tip collapse="true"}
## When to use Holt-Winters methods
- Holt-Winters methods are appropriate for data with a **trend** and **seasonal** pattern.
- Use an **additive model** when the seasonal fluctuations are roughly constant over time.
- Use a **multiplicative model** when the seasonal variation increase or decrease over time.
- The proper benchmark method to compare against is the **seasonal naïve** method. for seasonal data.
  - If the data contains both **trend** and **seasonality**, then A **decomposition model** using **STL**^[as the decomposition method] + **Drift**^[for the seasonally adjusted series] + **SNAIVE**^[for the seasonal component] is often a strong competitor.

:::

::: {.content-hidden unless-format="revealjs"}

## Forecasting Australian holiday trips {auto-animate="true"}

```{r}
#| label: hw_1

aus_holidays 
```



:::